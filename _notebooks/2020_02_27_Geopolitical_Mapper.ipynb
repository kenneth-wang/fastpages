{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-02-27-Geopolitical-Mapper",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwwjLE87tj9e",
        "colab_type": "text"
      },
      "source": [
        "# Mapping the world\n",
        "> Sentiment analysis of geopolitical relations using ALBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3US6CQoKu2sB",
        "colab_type": "text"
      },
      "source": [
        "# About\n",
        "\n",
        "It feels like the stock market tend to move in tandem with the political headlines. Benjamin Graham, the father of value investing once quoted **\"In the short run, the market is a voting machine but in the long run, it is a weighting machine.\"** I'm sure you have witnessed headlines such as **\"Dow ends down 2.4% on escalating US-China trade war\"** before. Being able to sift through the noise in the headlines could make the media an unexpected ally for investing. In response to demand for such forms of alternative data, [Bloomberg](https://www.bloomberg.com/professional/sentiment-analysis-white-papers/) introduced a tool to generate sentiments from news and social media data. In this blog post, we'll walk through the steps to analyze text data and **generate sentiments out of the relationships between countries by using ALBERT**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ7t_tLvwODU",
        "colab_type": "text"
      },
      "source": [
        "# What is ALBERT?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVZ8lU4yUtIw",
        "colab_type": "text"
      },
      "source": [
        "![](my_icons/geopolitical_mapper/bert_cropped.JPG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpJ6MKOM5PUJ",
        "colab_type": "text"
      },
      "source": [
        "Ok what is **ALBERT** exactly? ALBERT stands for \"A Lite BERT For Self-Supervised Learning of Language Representations\". ALBERT was introduced by Google as a **newly improved version of BERT**, or Bidirectional Encoder Representations with Transformers. It achieved state-of-the art results on three popular benchmark tests for nautral language understanding (GLUE, SQUAD and RACE). ALBERT improves on BERT by:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBqNHRNy0Zs7",
        "colab_type": "text"
      },
      "source": [
        "* **utilizing factorized embedding parametrization**.\n",
        "From a language modelling perspective, input-level embeddings are context-independent representations of the words (eg. \"bank\"), whereas the hidden-layer embeddings are meant to learn context-dependent representations (eg. \"bank\" in the context of financial transactions or river-flow management). Traditionally the sizes of the input-level and hidden layer embeddings are the same and pegged to one another. ALBERT takes a different approach by reducing the size of the input-level embeddings (128), while keeping hidden-layer embeddings at a higher dimension (768). With this, ALBERT managed to reduce the number of parameters drastically at the expense of a minor drop in performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro1DhoE3wsTY",
        "colab_type": "text"
      },
      "source": [
        "* **implementing cross-layer parameter sharing**.\n",
        "The authors implemented cross-layer parameter (feed-forward network parameters and attention parameters) sharing and results show that weight-sharing has an effect on stabilizing network parameters. As shown below, the differences (L2/ Cosine Similarity measures) between the input and output embeddings for ALBERT do not fluctuate as vigorously when compared to BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MWZTEgSwtWi",
        "colab_type": "text"
      },
      "source": [
        "![](my_icons/geopolitical_mapper/albert_cross_layer.JPG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkBIH2wZwnnt",
        "colab_type": "text"
      },
      "source": [
        "* **making amendments to the Sentence Order Prediction training task**. During the training phase, BERT receives two sentences each time and it needs to predict whether the second sentence in the pair, has been swapped with a sentence **from another document**. ALBERT implements a similar methodolgy, however it chooses instead to predict whether the order of two consecutive sentences **in the same document** have been swapped. The authors felt that the task of predicting the order of sentences is a more challenging pretraining task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi4MqTDVx_Hu",
        "colab_type": "text"
      },
      "source": [
        "Due to the design choices of the authors, the ALBERT models have a **smaller set of parameters**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4UBCLAOyQ7u",
        "colab_type": "text"
      },
      "source": [
        "![](my_icons/geopolitical_mapper/albert_parameters.JPG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx8OH-_66smG",
        "colab_type": "text"
      },
      "source": [
        "# Project directory structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz5xSeK66w8d",
        "colab_type": "text"
      },
      "source": [
        "The files that we will be referring to can be found [here](https://drive.google.com/open?id=1P6vzA168DovwZGtTD5OnYCMB-jTGlAdL). You can refer to the project structure below to find the locations of the files we need. We will be using **SQUAD's SST-2** dataset to finetune the ALBERT model before using **transfer learning** to train on our own data. We will use **Wikipedia's API** to extract text data that outlines the relationships between countries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT_5mPVv8PGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "geopolitical_mapper/\n",
        "\n",
        "_______ data/\n",
        "___________ SST-2/ # SST-2 dataset\n",
        "___________ Wiki/ # Wikipedia/ country-related data\n",
        "______________ countries.csv # list of countries in the world\n",
        "______________ country_ISO.txt # mapping of countries and their ISO code\n",
        "______________ wiki_relations.csv # wikipedia summaries of country relationships\n",
        "______________ dev.tsv # validation dataset \n",
        "______________ train.tsv # training dataset\n",
        "______________ sent_l_.csv # labeled dataset (without labels)\n",
        "______________ sent_ld.csv # labeled dataset (with labels)\n",
        "______________ sent_ul.csv # unlabeled dataset\n",
        "\n",
        "_______ model/ # Finetuned ALBERT model weights and checkpoints\n",
        "\n",
        "_______ 2020-02-27-Geopolitical-Mapper.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVc2GYDk12uE",
        "colab_type": "text"
      },
      "source": [
        "# Requirements\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THR0EcBE6CGB",
        "colab_type": "text"
      },
      "source": [
        "Let's start coding! Let's install the packages we need and import them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg0_jl7l2Wyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#collapse-hide\n",
        "%%capture\n",
        "\n",
        "!pip install bs4\n",
        "!pip install plotly\n",
        "!pip install requests\n",
        "!pip install sklearn\n",
        "!pip install spacy\n",
        "!pip install tensorflow==2.0.0\n",
        "!pip install tensorflow-gpu==2.0.0\n",
        "!pip install transformers==2.3.0\n",
        "!pip install wikipedia"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiPJA0kQ46Yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#collapse-hide\n",
        "import csv\n",
        "import itertools\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "\n",
        "import spacy\n",
        "import urllib.request\n",
        "import wikipedia\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, \\\n",
        "                            accuracy_score\n",
        "                            \n",
        "from spacy.lang.en import English\n",
        "from transformers import AlbertTokenizer, glue_convert_examples_to_features\n",
        "from transformers.data.processors import utils\n",
        "from transformers.modeling_tf_albert import TFAlbertForSequenceClassification\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, \\\n",
        "                                       EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcVrOpZwKNYk",
        "colab_type": "text"
      },
      "source": [
        "If you are running the notebook using Google Colab, remember to mount the directory that you are working from."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXX4O1mvKLz2",
        "colab_type": "code",
        "outputId": "f92f370b-9b47-4ad1-cbe4-5f0a785ea0bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "#collapse-hide\n",
        "%%capture\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "%cd /content/gdrive/My Drive/Colab Notebooks/ssh_files/geopolitical_mapper"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8huJQo_twN_A",
        "colab_type": "text"
      },
      "source": [
        "# Get alternative names of countries\n",
        "\n",
        "One of the biggest problems we face is that **each country can have multiple naming conventions**. For example, depending on the data that you use, **\"United States\"** might be named as **\"United States of America\" or \"USA\"**. Hence we need to look for a source that give us the different naming conventions for each of the countries. Thankfully we are able to source the names from a [Wikipage](https://en.wikipedia.org/wiki/List_of_alternative_country_names)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vce0A93dhdEd",
        "colab_type": "text"
      },
      "source": [
        "![](my_icons/geopolitical_mapper/wikipedia_table.JPG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNorXoou-zRt",
        "colab_type": "text"
      },
      "source": [
        "**Each of the tables in the Wikipage has two columns.** The column on the left, lists down the \"standardized names\" of the countries in alphabetical order..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU5fTC_t4OfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "website_url = requests.get('https://en.wikipedia.org/wiki/List_of_alternative_country_names').text\n",
        "\n",
        "soup = BeautifulSoup(website_url,'lxml')\n",
        "tables = soup.find_all('table',{'class':'wikitable'})\n",
        "\n",
        "countries = []\n",
        "\n",
        "## Left column - \"Description\"\n",
        "# Each table contains countries that start with a certain alphabet\n",
        "for table in tables:\n",
        "  rows = table.find_all('tr')\n",
        "  \n",
        "  # Gather countries with the specific alphabet\n",
        "  \n",
        "  countries_alphabet = [row.find('a').get('title') \\\n",
        "                        for i, row in enumerate(rows) if i != 0 ]\n",
        "\n",
        "  for country in countries_alphabet:\n",
        "    countries.append(country)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CSTdW55-oJH",
        "colab_type": "text"
      },
      "source": [
        "...while the columns on the right lists down the alternative names of the countries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mazdZgEB82T4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "countries_alt_names = []\n",
        "\n",
        "# Right column - Other name(s) or older name(s)\n",
        "for table in tables:\n",
        "  rows = table.find_all('tr')\n",
        "\n",
        "  for i, r in enumerate(rows):\n",
        "    \n",
        "    # Exclude table headers\n",
        "    if i != 0:\n",
        "      country_alt_name = [name.text for name in r.findAll('b')]\n",
        "      \n",
        "      if country_alt_name:\n",
        "        countries_alt_names.append(country_alt_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JRcdjpv_I3n",
        "colab_type": "text"
      },
      "source": [
        "After scrapping the table from the Wikipage, we can **create a dictionary** `alt_names_to_countries` that maps each alternative name of the countries to their standardized name. (eg. \"USA\": \"United States\"). In the process of doing so we will:\n",
        "* convert all letters to lower case\n",
        "* remove \"the\"\n",
        "* remove any empty spaces \" \".\n",
        "\n",
        "With these changes, names such as **\"The United States of America\"** will be modified to **\"united_states_of_america\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0ivUL0i-bLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First we group each country with their respective alternative names\n",
        "countries_to_alt_names_raw = {c:n for c, n in zip(countries, countries_alt_names)}\n",
        "\n",
        "# Map each alternative name to the default country name\n",
        "alt_names_to_countries = {v[i]:k for k, v in countries_to_alt_names_raw.items() \\\n",
        "                          for i in range(len(v))}\n",
        "\n",
        "# We lowercase the names; Remove \"the\" and '' that are contained in the names\n",
        "alt_names_to_countries = {k.lower().replace(\"the \", \"\"): v.lower().replace(\"the \", \"\") \\\n",
        "                          for k, v in alt_names_to_countries.items()}\n",
        "\n",
        "alt_names_to_countries = {k.lower().replace(\" \", \"_\"): v.lower().replace(\" \", \"_\") \\\n",
        "                          for k, v in alt_names_to_countries.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDyHNAHCDDwu",
        "colab_type": "text"
      },
      "source": [
        "We **remove names that are empty strings** and **add some names** that were missed out by the Wikipage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Cs6UcKoDDGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove empty strings\n",
        "alt_names_to_countries.pop('', None)\n",
        "\n",
        "# Add names\n",
        "alt_names_to_countries['angola'] = 'angola'\n",
        "alt_names_to_countries['equatorial_guinea'] = 'equatorial_guinea'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp8KdytAEOJK",
        "colab_type": "text"
      },
      "source": [
        "The **mappings of standardized names with themselves** are valid mappings as well. Let's add them in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYXcdBM5FDhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "default_countries = list(set(alt_names_to_countries.values()))\n",
        "\n",
        "for c in default_countries:\n",
        "  alt_names_to_countries.update({c:c})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTMCoFSOFW_N",
        "colab_type": "text"
      },
      "source": [
        "Let's convert the dictionary `alt_names_to_countries` into a dataframe `alt_names_df` for easier visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlN5wCTPFcqr",
        "colab_type": "code",
        "outputId": "6260eab8-45bd-4fe8-aca8-ca9f484dac94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "alt_names_df = pd.DataFrame.from_dict(alt_names_to_countries, \\\n",
        "                                      orient='index').reset_index()\n",
        "\n",
        "alt_names_df = alt_names_df.rename(columns={'index': 'Alternative_Name', \\\n",
        "                                            0:'Name'})\n",
        "\n",
        "alt_names_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Alternative_Name</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>republic_of_abkhazia</td>\n",
              "      <td>abkhazia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aphsny_axwynthkharra</td>\n",
              "      <td>abkhazia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>respublika_abkhaziya</td>\n",
              "      <td>abkhazia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>autonomous_republic_of_abkhazia</td>\n",
              "      <td>abkhazia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>islamic_republic_of_afghanistan</td>\n",
              "      <td>afghanistan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>da_afġānistān_islāmī_jumhoryat</td>\n",
              "      <td>afghanistan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>jomhūrīyyeh_eslāmīyyeh_afġānestān</td>\n",
              "      <td>afghanistan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>republic_of_albania</td>\n",
              "      <td>albania</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>republika_e_shqipërisë</td>\n",
              "      <td>albania</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>arnavutluk</td>\n",
              "      <td>albania</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Alternative_Name         Name\n",
              "0               republic_of_abkhazia     abkhazia\n",
              "1               aphsny_axwynthkharra     abkhazia\n",
              "2               respublika_abkhaziya     abkhazia\n",
              "3    autonomous_republic_of_abkhazia     abkhazia\n",
              "4    islamic_republic_of_afghanistan  afghanistan\n",
              "5     da_afġānistān_islāmī_jumhoryat  afghanistan\n",
              "6  jomhūrīyyeh_eslāmīyyeh_afġānestān  afghanistan\n",
              "7                republic_of_albania      albania\n",
              "8             republika_e_shqipërisë      albania\n",
              "9                         arnavutluk      albania"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWsl-57zxiq8",
        "colab_type": "text"
      },
      "source": [
        "As it will be easier for us to work with country names when they are standardized, let's **create a function** `get_std_names` that converts the raw names to the standardized (std) names by using the mappings in `alt_names_to_countries`. Sometimes raw names that we deal with may be upper cased or contain words/characters such as \"the\", brackets and punctuations. We will clean them up before looking for their standardized names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FL9MBKqxhS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_std_names(df, col_name, alt_names_to_countries):\n",
        "    \"\"\"\n",
        "    Creates a new column of standardized country names for a dataframe\n",
        "    \n",
        "    args:\n",
        "    ------\n",
        "        df: (pd.DataFrame) initial dataframe\n",
        "        col_name: (str) name of the column containing the raw country names \n",
        "                        eg. \"Country_A\"\n",
        "        alt_names_to_countries: (dict) contains country mappings\n",
        "    Return:\n",
        "    ------\n",
        "        New dataframe with an additional column with the suffix \"_Std\" \n",
        "        representing the standardized country names eg. \"Country_A_Std\"\n",
        "    \"\"\"\n",
        "\n",
        "    country_names = df[col_name].tolist()\n",
        "    # lower case\n",
        "    country_names = [c.lower() for c in country_names]\n",
        "    # remove the\n",
        "    country_names = [c.replace(\"the \",\"\") for c in country_names]\n",
        "    # add underscore\n",
        "    country_names = [\"_\".join(c.split()) for c in country_names]\n",
        "    # remove '(' ')'\n",
        "    country_names = [c.replace(\"(\", \"\") for c in country_names]\n",
        "    country_names = [c.replace(\")\", \"\") for c in country_names]\n",
        "    # remove .\n",
        "    country_names = [c.replace(\".\", \"\") for c in country_names]\n",
        "    \n",
        "    std_names = []\n",
        "    for name in country_names:\n",
        "      try:\n",
        "        std_names.append(alt_names_to_countries[name])\n",
        "      except:\n",
        "        std_names.append(name)\n",
        "\n",
        "    df[col_name + '_Std'] = std_names\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjIOHIyAGvVW",
        "colab_type": "text"
      },
      "source": [
        "Great, now let's put the `get_std_names` function to good use! As you can see, we have an **additional column** `Country_Std` that contains the standardized names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSv7nWebxxvI",
        "colab_type": "code",
        "outputId": "8a1c6f05-d437-4313-bc2c-84fe93a2206e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "countries_df = pd.read_csv('./data/Wiki/countries.csv')\n",
        "\n",
        "countries_df = get_std_names(countries_df, 'Country', alt_names_to_countries)\n",
        "countries_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Continent</th>\n",
              "      <th>Country</th>\n",
              "      <th>Country_Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Africa</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>algeria</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Africa</td>\n",
              "      <td>Angola</td>\n",
              "      <td>angola</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Africa</td>\n",
              "      <td>Benin</td>\n",
              "      <td>benin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Africa</td>\n",
              "      <td>Botswana</td>\n",
              "      <td>botswana</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Africa</td>\n",
              "      <td>Burkina</td>\n",
              "      <td>burkina</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Africa</td>\n",
              "      <td>Burundi</td>\n",
              "      <td>burundi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Africa</td>\n",
              "      <td>Cameroon</td>\n",
              "      <td>cameroon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Africa</td>\n",
              "      <td>Cape Verde</td>\n",
              "      <td>cape_verde</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Africa</td>\n",
              "      <td>Central African Republic</td>\n",
              "      <td>central_african_republic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Africa</td>\n",
              "      <td>Chad</td>\n",
              "      <td>chad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Continent                   Country               Country_Std\n",
              "0    Africa                   Algeria                   algeria\n",
              "1    Africa                    Angola                    angola\n",
              "2    Africa                     Benin                     benin\n",
              "3    Africa                  Botswana                  botswana\n",
              "4    Africa                   Burkina                   burkina\n",
              "5    Africa                   Burundi                   burundi\n",
              "6    Africa                  Cameroon                  cameroon\n",
              "7    Africa                Cape Verde                cape_verde\n",
              "8    Africa  Central African Republic  central_african_republic\n",
              "9    Africa                      Chad                      chad"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwIbzTN6gTWR",
        "colab_type": "text"
      },
      "source": [
        "With the names of the countries all accounted for, we will gather the total number of pair-wise relations between countries that we have to analyze the sentiments for. We will grab a list of unique countries that we have, group them up and remove any duplicate pairs. And bam! We have **18,336 country pairs** that we have to work with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2b3H-VDGsFr",
        "colab_type": "code",
        "outputId": "1cfbc99e-21a4-4d35-f8d4-b6ce57c5f082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "country_groups = []\n",
        "\n",
        "unique_countries = countries_df['Country_Std'].tolist()\n",
        "\n",
        "for i in range(len(unique_countries)):\n",
        "  for j in range(len(unique_countries)):\n",
        "    country_A = unique_countries[i]\n",
        "    country_B = unique_countries[j]\n",
        "\n",
        "    # We are not interested in relations of countries with itself\n",
        "    if country_A != country_B:\n",
        "      country_groups.append([country_A, country_B])\n",
        "\n",
        "# Sort by alphabetical order\n",
        "sorted_country_groups = [tuple(sorted(el)) for el in country_groups]\n",
        "\n",
        "# Remove any duplicates\n",
        "unique_country_groups = list(dict.fromkeys(sorted_country_groups))\n",
        "\n",
        "print(len(unique_country_groups))\n",
        "print(unique_country_groups[0:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18336\n",
            "[('algeria', 'angola'), ('algeria', 'benin'), ('algeria', 'botswana'), ('algeria', 'burkina'), ('algeria', 'burundi')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRiUIPMywN6z",
        "colab_type": "text"
      },
      "source": [
        "# Gathering the data from Wikipedia!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfvAtraIVIxR",
        "colab_type": "text"
      },
      "source": [
        "![](my_icons/geopolitical_mapper/singapore_china_relations.JPG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQzam9yYhRti",
        "colab_type": "text"
      },
      "source": [
        "To gather the data we need, one option will be to scrape news headlines from the web. But one of the problems that we face when doing a simple search with \"China-United States relations\" on Google is that you are **unable to differentiate facts from commentaries**. The following is a headline from CNN : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IeAGJnFEnqp",
        "colab_type": "text"
      },
      "source": [
        "*The US-China trade war isn't getting better. This week showed why it could get worse.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7jp4v5DEjb3",
        "colab_type": "text"
      },
      "source": [
        "Including such headlines in our data could **affect the reliability of our predictions.** Thankfully we are able to find an alternative data source from Wikipedia that offers summaries of actual incidents that occured between countries. Here is an **example for the relationship between United States and Singapore** retrieved from the [**summary section of the Singapore-United States Relations wikipedia page**](https://en.wikipedia.org/wiki/Singapore%E2%80%93United_States_relations):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P6tMK0HKQVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Create empty dataframe\n",
        "# wiki_df = pd.DataFrame(columns = ['Summary', 'URL', 'Country_Pair'])\n",
        "\n",
        "\n",
        "# for c in unique_countries:\n",
        "#   # For each country, identify which country relations are \n",
        "#   # available on wikipedia\n",
        "#   avail_relations = str(c + \" relations\")\n",
        "\n",
        "#   # For each available result\n",
        "#   for r in wikipedia.search(avail_relations):\n",
        "\n",
        "#       # Filter out results are not related to the relations of countries\n",
        "#       if \"–\" in r and \"relations\" in r:\n",
        "#         try:\n",
        "#           # Retrieve the summary paragraph on the wikipage\n",
        "#           summary = wikipedia.summary(r)\n",
        "\n",
        "#           # Retrieve the url\n",
        "#           url = wikipedia.page(r).url\n",
        "\n",
        "#           wiki_df = wiki_df.append({'Summary': summary, 'URL': url, \\\n",
        "#                                     'Country_Pair': r},ignore_index=True)\n",
        "#         except:\n",
        "#           pass\n",
        "\n",
        "# wiki_df.to_csv('./data/Wiki/wiki_relations.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnQB7WsINH5g",
        "colab_type": "text"
      },
      "source": [
        "Unfortunately, Wikipedia does not cover all 18,336 pairs that we are interested in. We are only able to retrieve the information for **1,463 pairs**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO0ZZlaBhCHG",
        "colab_type": "code",
        "outputId": "ef47b290-12d7-414c-ba1e-5638e10edb01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "wiki_df = pd.read_csv('./data/Wiki/wiki_relations.csv')\n",
        "\n",
        "print(wiki_df.shape)\n",
        "wiki_df[['Summary', 'URL', 'Country_Pair']].head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1463, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>URL</th>\n",
              "      <th>Country_Pair</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Relations between France and Algeria span more...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Algeria%E2%80%93...</td>\n",
              "      <td>Algeria–France relations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Algeria – United States relations are the inte...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Algeria%E2%80%93...</td>\n",
              "      <td>Algeria–United States relations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Algeria–Libya relations are longstanding betwe...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Algeria%E2%80%93...</td>\n",
              "      <td>Algeria–Libya relations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Algeria–Morocco relations have been dominated ...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Algeria%E2%80%93...</td>\n",
              "      <td>Algeria–Morocco relations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Algeria–Turkey relations are foreign relations...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Algeria%E2%80%93...</td>\n",
              "      <td>Algeria–Turkey relations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Algeria–Russia relations (Russian: Российско–а...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Algeria%E2%80%93...</td>\n",
              "      <td>Algeria–Russia relations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Algeria–Israel relations refers to the current...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Algeria%E2%80%93...</td>\n",
              "      <td>Algeria–Israel relations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Algeria–Indonesia relations refers to the bila...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Algeria%E2%80%93...</td>\n",
              "      <td>Algeria–Indonesia relations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Algeria–China relations (also, Sino-Algerian r...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Algeria%E2%80%93...</td>\n",
              "      <td>Algeria–China relations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Angola – United States relations are diplomati...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Angola%E2%80%93U...</td>\n",
              "      <td>Angola–United States relations</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Summary  ...                     Country_Pair\n",
              "0  Relations between France and Algeria span more...  ...         Algeria–France relations\n",
              "1  Algeria – United States relations are the inte...  ...  Algeria–United States relations\n",
              "2  Algeria–Libya relations are longstanding betwe...  ...          Algeria–Libya relations\n",
              "3  Algeria–Morocco relations have been dominated ...  ...        Algeria–Morocco relations\n",
              "4  Algeria–Turkey relations are foreign relations...  ...         Algeria–Turkey relations\n",
              "5  Algeria–Russia relations (Russian: Российско–а...  ...         Algeria–Russia relations\n",
              "6  Algeria–Israel relations refers to the current...  ...         Algeria–Israel relations\n",
              "7  Algeria–Indonesia relations refers to the bila...  ...      Algeria–Indonesia relations\n",
              "8  Algeria–China relations (also, Sino-Algerian r...  ...          Algeria–China relations\n",
              "9  Angola – United States relations are diplomati...  ...   Angola–United States relations\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmHtmYACPiCm",
        "colab_type": "text"
      },
      "source": [
        "Some of the summaries that we have retrieved from Wikipedia were **empty strings**. Let's remove them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0j1VtF3NHdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki_df = wiki_df.fillna(\"EMPTY\")\n",
        "wiki_df = wiki_df[wiki_df['Summary'] != \"EMPTY\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Qn2I_Q9M2M8",
        "colab_type": "text"
      },
      "source": [
        "Let's split the pairs in `Country_Pairs` into their **constituent countries** and place them in separate columns `Country_A` and `Country_B`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUFO60n-Pcdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_country_pair(wiki_country_pairs):\n",
        "    \"\"\"\n",
        "    Split country_pairs found via wikipedia (eg. \"Algebria-France relations\")\n",
        "    \n",
        "    args:\n",
        "    ------\n",
        "        wiki_country_pairs: (list) country_pairs to be split\n",
        "    Return:\n",
        "    ------\n",
        "        countries_A: (list) countries on the left of \"-\" separator\n",
        "        countries_B: (list) countries on the right of \"-\" separator\n",
        "    \"\"\"\n",
        "\n",
        "    country_pairs = [p.replace(\" relations\", \"\") for p in wiki_country_pairs]\n",
        "    countries_A = [p.split(\"–\")[0] for p in country_pairs]\n",
        "    countries_B = [p.split(\"–\")[1] for p in country_pairs]\n",
        "\n",
        "    return countries_A , countries_B"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9YG_TYUXzYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki_df['Country_A'], wiki_df['Country_B'] = split_country_pair(wiki_df['Country_Pair'].tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0xTtFr6SD5t",
        "colab_type": "text"
      },
      "source": [
        "With the country pairs separated we can retrieve their standardized `std` names. Remember the `get_std_names` function that we created earlier?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYdfOzuKQaSD",
        "colab_type": "code",
        "outputId": "4df749d7-917b-4c46-a7a9-8ade8f49cffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "wiki_df = get_std_names(wiki_df, 'Country_A', alt_names_to_countries)\n",
        "wiki_df = get_std_names(wiki_df, 'Country_B', alt_names_to_countries)\n",
        "\n",
        "wiki_df.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>URL</th>\n",
              "      <th>Country_Pair</th>\n",
              "      <th>Country_A</th>\n",
              "      <th>Country_B</th>\n",
              "      <th>Country_A_Std</th>\n",
              "      <th>Country_B_Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Relations between France and Algeria span more...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Algeria%E2%80%93...</td>\n",
              "      <td>Algeria–France relations</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>France</td>\n",
              "      <td>algeria</td>\n",
              "      <td>france</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Algeria – United States relations are the inte...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Algeria%E2%80%93...</td>\n",
              "      <td>Algeria–United States relations</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>United States</td>\n",
              "      <td>algeria</td>\n",
              "      <td>united_states</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Algeria–Libya relations are longstanding betwe...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Algeria%E2%80%93...</td>\n",
              "      <td>Algeria–Libya relations</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>Libya</td>\n",
              "      <td>algeria</td>\n",
              "      <td>libya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Algeria–Morocco relations have been dominated ...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Algeria%E2%80%93...</td>\n",
              "      <td>Algeria–Morocco relations</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>Morocco</td>\n",
              "      <td>algeria</td>\n",
              "      <td>morocco</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Algeria–Turkey relations are foreign relations...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Algeria%E2%80%93...</td>\n",
              "      <td>Algeria–Turkey relations</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>Turkey</td>\n",
              "      <td>algeria</td>\n",
              "      <td>turkey</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Summary  ...  Country_B_Std\n",
              "0  Relations between France and Algeria span more...  ...         france\n",
              "1  Algeria – United States relations are the inte...  ...  united_states\n",
              "2  Algeria–Libya relations are longstanding betwe...  ...          libya\n",
              "3  Algeria–Morocco relations have been dominated ...  ...        morocco\n",
              "4  Algeria–Turkey relations are foreign relations...  ...         turkey\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwMWVBJEu2cf",
        "colab_type": "text"
      },
      "source": [
        "# Generate labeled data for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJiSQdJ8YF-q",
        "colab_type": "text"
      },
      "source": [
        "![](my_icons/geopolitical_mapper/google_machine_learning_code.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-Nm2x3XS6gw",
        "colab_type": "text"
      },
      "source": [
        "Creating your own **training dataset** is one of the most challenging task in the real world. To finetune ALBERT for our use case, we will need to create a training dataset. \n",
        "\n",
        "Due to time limitations, **let's label 10% of the data** `l` while the **remaining 90% of the data will remain unlabeled** `ul`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0kVgwyXT6wY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = np.array(wiki_df.index.tolist())\n",
        "\n",
        "X_l, X_ul = train_test_split(idx, train_size=0.10, random_state=42)\n",
        "wiki_l_df = wiki_df.loc[X_l]\n",
        "wiki_ul_df = wiki_df.loc[X_ul]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTBYHBJD-KNf",
        "colab_type": "text"
      },
      "source": [
        "### Splitting wikipedia summary paragraphs into sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88o9AP_RUhjy",
        "colab_type": "text"
      },
      "source": [
        "Currently our training data exists in in the form of a paragraphs. We will can **split the summary paragraphs into individual sentences** before labeling them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1a0vmk3sZH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_summaries(summaries, country_As, country_Bs):\n",
        "    \"\"\"\n",
        "    Split wikipedia summaries of each country pair into individual sentences\n",
        "    \n",
        "    args:\n",
        "    ------\n",
        "        summaries: (list) wikipedia summaries\n",
        "        country_As: (list) countries in Country_A column\n",
        "        country_Bs: (list) countries in Country_B column\n",
        "    Return:\n",
        "    ------\n",
        "        sent_df: (pd.DataFrame) a new dataframe with each row representing\n",
        "                  one sentence of a wikipedia summary\n",
        "    \"\"\"\n",
        "\n",
        "    nlp = English()\n",
        "    nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
        "\n",
        "    sents = [sent.text for summary in summaries for sent in nlp(summary).sents]\n",
        "    sents = [s.replace(\"\\n\", \"\") for s in sents]\n",
        "    sents\n",
        "\n",
        "    # We will have to replicate the names of the country as many times\n",
        "    # as the number of sentences\n",
        "    sents_counts = [len(list(nlp(summary).sents)) for summary in summaries]\n",
        "\n",
        "    country_A_freq = list(zip(country_As, sents_counts))\n",
        "    country_B_freq = list(zip(country_Bs, sents_counts))\n",
        "    \n",
        "    country_A_rep = list(itertools.chain.from_iterable(itertools.repeat(x[0], x[1]) for x in country_A_freq))\n",
        "    country_B_rep = list(itertools.chain.from_iterable(itertools.repeat(x[0], x[1]) for x in country_B_freq))\n",
        "\n",
        "    # Create dataframe of sentences\n",
        "    d = {'Summary_Sentence':sents, 'Country_A': country_A_rep, \\\n",
        "         'Country_B': country_B_rep}\n",
        "\n",
        "    sent_df = pd.DataFrame(d)\n",
        "    sent_df['Country_Pair'] = sent_df['Country_A'] + '_' + sent_df['Country_B']\n",
        "\n",
        "    return sent_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7reoF7ejoZP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_l_df = split_summaries(wiki_l_df['Summary'].tolist(),\n",
        "                            wiki_l_df['Country_A'].tolist(),\n",
        "                            wiki_l_df['Country_B'].tolist())\n",
        "\n",
        "sent_ul_df = split_summaries(wiki_ul_df['Summary'].tolist(),\n",
        "                             wiki_ul_df['Country_A'].tolist(),\n",
        "                             wiki_ul_df['Country_B'].tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N0hP4k85zki",
        "colab_type": "code",
        "outputId": "8e80935d-d724-4407-f961-e98600652001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "sent_l_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary_Sentence</th>\n",
              "      <th>Country_A</th>\n",
              "      <th>Country_B</th>\n",
              "      <th>Country_Pair</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>China–Indonesia relations refer to the foreign...</td>\n",
              "      <td>China</td>\n",
              "      <td>Indonesia</td>\n",
              "      <td>China_Indonesia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The relations between two nations have been on...</td>\n",
              "      <td>China</td>\n",
              "      <td>Indonesia</td>\n",
              "      <td>China_Indonesia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>However, the diplomatic relationship between t...</td>\n",
              "      <td>China</td>\n",
              "      <td>Indonesia</td>\n",
              "      <td>China_Indonesia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>China has an embassy in Jakarta and consulates...</td>\n",
              "      <td>China</td>\n",
              "      <td>Indonesia</td>\n",
              "      <td>China_Indonesia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Both countries are among the largest nations i...</td>\n",
              "      <td>China</td>\n",
              "      <td>Indonesia</td>\n",
              "      <td>China_Indonesia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Both nations are the members of APEC and G-20 ...</td>\n",
              "      <td>China</td>\n",
              "      <td>Indonesia</td>\n",
              "      <td>China_Indonesia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>According to a 2014 BBC World Service Poll, th...</td>\n",
              "      <td>China</td>\n",
              "      <td>Indonesia</td>\n",
              "      <td>China_Indonesia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Djibouti – United States relations are bilater...</td>\n",
              "      <td>Djibouti</td>\n",
              "      <td>United States</td>\n",
              "      <td>Djibouti_United States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Poland–Russia relations (Polish: Stosunki pols...</td>\n",
              "      <td>Poland</td>\n",
              "      <td>Russia</td>\n",
              "      <td>Poland_Russia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Over centuries, there have been several Polish...</td>\n",
              "      <td>Poland</td>\n",
              "      <td>Russia</td>\n",
              "      <td>Poland_Russia</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Summary_Sentence  ...            Country_Pair\n",
              "0  China–Indonesia relations refer to the foreign...  ...         China_Indonesia\n",
              "1  The relations between two nations have been on...  ...         China_Indonesia\n",
              "2  However, the diplomatic relationship between t...  ...         China_Indonesia\n",
              "3  China has an embassy in Jakarta and consulates...  ...         China_Indonesia\n",
              "4  Both countries are among the largest nations i...  ...         China_Indonesia\n",
              "5  Both nations are the members of APEC and G-20 ...  ...         China_Indonesia\n",
              "6  According to a 2014 BBC World Service Poll, th...  ...         China_Indonesia\n",
              "7  Djibouti – United States relations are bilater...  ...  Djibouti_United States\n",
              "8  Poland–Russia relations (Polish: Stosunki pols...  ...           Poland_Russia\n",
              "9  Over centuries, there have been several Polish...  ...           Poland_Russia\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcVm2CDML8aA",
        "colab_type": "text"
      },
      "source": [
        "### Some data cleaning to do - Removing irrelevant sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQu2CvOf6MF3",
        "colab_type": "text"
      },
      "source": [
        "There are some sentences that do not offer any insights into the relationships between countries. For example:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9fd5KHf0--H",
        "colab_type": "text"
      },
      "source": [
        "*United States – Singapore relations are bilateral relations between the United States and Singapore.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLFjnA2I1CTY",
        "colab_type": "text"
      },
      "source": [
        " It will be good for us to remove them to increase the performance of our model. Unfortunately, **these sentences come in various forms**. Let's take a look at another example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fG1rW1f1MKS",
        "colab_type": "text"
      },
      "source": [
        "*The Bahamas–United States relations refers to foreign relations between the Bahamas and States*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg-yUU0W1TA6",
        "colab_type": "text"
      },
      "source": [
        "There are more examples below if you are interested to look at them. We will use **regex** to remove them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1a4b3452-f1ec-4a9e-ee6c-6296d0bc0f5e",
        "id": "_60NLr-Lpjsy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "regex_1 = '^(The|'')\\s?[a-zA-Z\\s]+(–|-|and)[a-zA-Z\\s]+ relations refer[s]?'\n",
        "\n",
        "regex_1_df = sent_ul_df[sent_ul_df['Summary_Sentence'].str.contains(regex_1, regex=True)]\n",
        "regex_1_df.head(5)['Summary_Sentence'].tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/strings.py:1843: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
            "  return func(self, *args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['French–American relations refers to the diplomatic, social, economic and cultural relations between France and the United States since 1776.',\n",
              " 'Trinidad and Tobago–Venezuela relations refers to the bilateral relations between the Republic of Trinidad and Tobago and the Bolivarian Republic of Venezuela.',\n",
              " 'Bangladesh–Ukraine relations refer to the bilateral relations between Bangladesh and Ukraine.',\n",
              " 'Mauritius–Russia relations refers to the bilateral relations of Russia and Mauritius.',\n",
              " 'Bangladesh–Brunei relations refer to the bilateral relations between Bangladesh and Brunei.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egXLVUPfWnPn",
        "colab_type": "code",
        "outputId": "b1be28bd-cbd8-417d-c089-8c3f5203dc74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "regex_2 = '^(The|'')\\s?[a-zA-Z\\s]+(–|-|and)[a-zA-Z\\s]+ relations (are|is)'\n",
        "\n",
        "regex_2_df = sent_ul_df[sent_ul_df['Summary_Sentence'].str.contains(regex_2, regex=True)]\n",
        "regex_2_df.head(5)['Summary_Sentence'].tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/strings.py:1843: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
            "  return func(self, *args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['British–Canadian relations are the relations between  Canada and the United Kingdom of Great Britain and Northern Ireland, being bilateral relations between their governments and wider relations between the 2 societies.',\n",
              " 'Bahrain–United Kingdom relations are bilateral relations between Kingdom of Bahrain and the United Kingdom of Great Britain and Northern Ireland.',\n",
              " 'Portugal–Russia relations are foreign relations between Portugal and Russia.',\n",
              " 'Cuba–Mexico relations are the diplomatic and bilateral relations between the Republic of Cuba and the United Mexican States.',\n",
              " 'Kyrgyzstan–Russia relations is the relationship between the two countries, Kyrgyzstan and Russia.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttgByVom9Kwb",
        "colab_type": "text"
      },
      "source": [
        "`remove_invalid_sents` will help us to remove all the different combinations that we have spotted so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNKgYcW0LjBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_invalid_sents(df):\n",
        "\n",
        "    # Remove empty sentences\n",
        "    df.replace(\"\", np.nan, inplace=True)\n",
        "    df.dropna(subset=[\"Summary_Sentence\"], inplace=True)\n",
        "\n",
        "    # Remove sentences with ...relations refers to...\n",
        "    regex_1 = '^(The|'')\\s?[a-zA-Z\\s]+(–|-|and)[a-zA-Z\\s]+ relations refer[s]?'\n",
        "    regex_2 = '^(The|'')\\s?[a-zA-Z\\s]+(–|-|and)[a-zA-Z\\s]+ relations (are|is)'\n",
        "\n",
        "    df = df[~df['Summary_Sentence'].str.contains(regex_1, regex=True)]\n",
        "    df = df[~df['Summary_Sentence'].str.contains(regex_2, regex=True)]\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKwUJwmHOP5g",
        "colab_type": "code",
        "outputId": "e1a481b3-942c-4013-bac7-c68e36b4797f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "sent_l_df = remove_invalid_sents(sent_l_df)\n",
        "sent_ul_df = remove_invalid_sents(sent_ul_df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/strings.py:1843: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
            "  return func(self, *args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf1vS-a_NEOU",
        "colab_type": "text"
      },
      "source": [
        "For now, we will exclude the summaries between **\"History of Japan\"** and \"Korea\" and instead analyze the relationship between **\"Japan\"** and \"Korea\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tba0LeFdNdOI",
        "colab_type": "code",
        "outputId": "12a4d533-1332-4ca4-d8f6-1440f9116268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "hoj = sent_l_df[sent_l_df['Country_A'] == 'History of Japan']\n",
        "hoj.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary_Sentence</th>\n",
              "      <th>Country_A</th>\n",
              "      <th>Country_B</th>\n",
              "      <th>Country_Pair</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>For over 15 centuries, the relationship betwee...</td>\n",
              "      <td>History of Japan</td>\n",
              "      <td>Korea</td>\n",
              "      <td>History of Japan_Korea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>During the ancient era, exchanges of cultures ...</td>\n",
              "      <td>History of Japan</td>\n",
              "      <td>Korea</td>\n",
              "      <td>History of Japan_Korea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Buddhism, Chinese-influenced cuisine, Han char...</td>\n",
              "      <td>History of Japan</td>\n",
              "      <td>Korea</td>\n",
              "      <td>History of Japan_Korea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Since 1945, relations involve three states: No...</td>\n",
              "      <td>History of Japan</td>\n",
              "      <td>Korea</td>\n",
              "      <td>History of Japan_Korea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Japan cut off Korea from Qing Chinese suzerain...</td>\n",
              "      <td>History of Japan</td>\n",
              "      <td>Korea</td>\n",
              "      <td>History of Japan_Korea</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     Summary_Sentence  ...            Country_Pair\n",
              "14  For over 15 centuries, the relationship betwee...  ...  History of Japan_Korea\n",
              "15  During the ancient era, exchanges of cultures ...  ...  History of Japan_Korea\n",
              "16  Buddhism, Chinese-influenced cuisine, Han char...  ...  History of Japan_Korea\n",
              "17  Since 1945, relations involve three states: No...  ...  History of Japan_Korea\n",
              "18  Japan cut off Korea from Qing Chinese suzerain...  ...  History of Japan_Korea\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFTQI6U5-x5w",
        "colab_type": "text"
      },
      "source": [
        "Let's save the data we have created into csv files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5bEVJtSLhlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sent_l_df.to_csv('./data/Wiki/sent_l.csv', index=False)\n",
        "sent_ul_df.to_csv('./data/Wiki/sent_ul.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_5tNwv822w_",
        "colab_type": "text"
      },
      "source": [
        "I have manually labeled close to **700 sentences**, giving them a label of **0, 1 and 2** for negative, positive and neutral sentiments respectively. Let's read the file to obtain the labels `ld`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et9Vrn3u22XD",
        "colab_type": "code",
        "outputId": "571c9a38-d3d5-4099-ec51-329ed150a6ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "sent_ld_all_df = pd.read_csv('./data/Wiki/sent_ld.csv')\n",
        "\n",
        "sent_ld_all_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary_Sentence</th>\n",
              "      <th>Label</th>\n",
              "      <th>Country_A</th>\n",
              "      <th>Country_B</th>\n",
              "      <th>Country_Pair</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The relations between two nations have been on...</td>\n",
              "      <td>1</td>\n",
              "      <td>China</td>\n",
              "      <td>Indonesia</td>\n",
              "      <td>China_Indonesia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>However, the diplomatic relationship between t...</td>\n",
              "      <td>0</td>\n",
              "      <td>China</td>\n",
              "      <td>Indonesia</td>\n",
              "      <td>China_Indonesia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>China has an embassy in Jakarta and consulates...</td>\n",
              "      <td>1</td>\n",
              "      <td>China</td>\n",
              "      <td>Indonesia</td>\n",
              "      <td>China_Indonesia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Both countries are among the largest nations i...</td>\n",
              "      <td>2</td>\n",
              "      <td>China</td>\n",
              "      <td>Indonesia</td>\n",
              "      <td>China_Indonesia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Both nations are the members of APEC and G-20 ...</td>\n",
              "      <td>1</td>\n",
              "      <td>China</td>\n",
              "      <td>Indonesia</td>\n",
              "      <td>China_Indonesia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>\\nAccording to a 2014 BBC World Service Poll, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>China</td>\n",
              "      <td>Indonesia</td>\n",
              "      <td>China_Indonesia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Poland–Russia relations (Polish: Stosunki pols...</td>\n",
              "      <td>0</td>\n",
              "      <td>Poland</td>\n",
              "      <td>Russia</td>\n",
              "      <td>Poland_Russia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Over centuries, there have been several Polish...</td>\n",
              "      <td>0</td>\n",
              "      <td>Poland</td>\n",
              "      <td>Russia</td>\n",
              "      <td>Poland_Russia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Polish–Russian relations entered a new phase f...</td>\n",
              "      <td>2</td>\n",
              "      <td>Poland</td>\n",
              "      <td>Russia</td>\n",
              "      <td>Poland_Russia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Since then Polish–Russian relations have at ti...</td>\n",
              "      <td>2</td>\n",
              "      <td>Poland</td>\n",
              "      <td>Russia</td>\n",
              "      <td>Poland_Russia</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Summary_Sentence  ...     Country_Pair\n",
              "0  The relations between two nations have been on...  ...  China_Indonesia\n",
              "1  However, the diplomatic relationship between t...  ...  China_Indonesia\n",
              "2  China has an embassy in Jakarta and consulates...  ...  China_Indonesia\n",
              "3  Both countries are among the largest nations i...  ...  China_Indonesia\n",
              "4  Both nations are the members of APEC and G-20 ...  ...  China_Indonesia\n",
              "5  \\nAccording to a 2014 BBC World Service Poll, ...  ...  China_Indonesia\n",
              "6  Poland–Russia relations (Polish: Stosunki pols...  ...    Poland_Russia\n",
              "7  Over centuries, there have been several Polish...  ...    Poland_Russia\n",
              "8  Polish–Russian relations entered a new phase f...  ...    Poland_Russia\n",
              "9  Since then Polish–Russian relations have at ti...  ...    Poland_Russia\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J5QbBxCWaje",
        "colab_type": "text"
      },
      "source": [
        "Let's step ahead a little. While working on this blog post, I did realise that the inclusion of sentences with **neutral sentiments** affects the performance of the model **negatively**. Below are some examples of these sentences. For now, let's **exclude them** and only train our model with sentences of positive and negative sentiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK-eV-tJXj9S",
        "colab_type": "code",
        "outputId": "79663a8b-1d9b-4705-a659-18c895bf8e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "sent_ld_neutral_df = sent_ld_all_df[sent_ld_all_df['Label'] == 2]\n",
        "sent_ld_neutral_df['Summary_Sentence'].tolist()[0:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Both countries are among the largest nations in Asia in terms of both area and population, China is the most populous nation on earth, while Indonesia has the 4th largest population in the world.',\n",
              " 'Polish–Russian relations entered a new phase following the fall of communism, 1989–1993.',\n",
              " 'Since then Polish–Russian relations have at times seen both improvement and deterioration.',\n",
              " 'The relationship was generally warm under the Russian President Boris Yeltsin (1991–99) until the NATO bombing of the Federal Republic of Yugoslavia in the spring of 1999, and has since deteriorated significantly.',\n",
              " 'Relations between the neighboring countries of Iran and the United Arab Emirates (UAE) are deeply historic, dating back centuries prior to the establishment of the modern-day United Arab Emirates; however today it has been described as up-and-down.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYKIiHf7t-_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_ld_df = sent_ld_all_df[sent_ld_all_df['Label'] != 2].reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsfsU2tiOevY",
        "colab_type": "text"
      },
      "source": [
        "# Generating training and development datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcskn_QaZX4J",
        "colab_type": "text"
      },
      "source": [
        "![](my_icons/geopolitical_mapper/tune_hyperparameters.JPG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvLzshbS-skj",
        "colab_type": "text"
      },
      "source": [
        "To tune our hyperparameters and prevent over/underfitting, we will need to generate a development (validation) dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v5-CZwg8LmQ",
        "colab_type": "text"
      },
      "source": [
        "While splitting the data, there is a need for us to **split by country pairs to prevent any leakage in information** about the countries' relations leaking from the training to development set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZKky3Ka6OsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "country_pairs = sent_ld_df['Country_Pair'].unique()\n",
        "country_pairs_to_num = {v:i for i,v in enumerate(country_pairs)}\n",
        "\n",
        "sent_ld_df['Group'] = sent_ld_df['Country_Pair'].map(country_pairs_to_num)\n",
        "\n",
        "idx = np.array(sent_ld_df.index.tolist())\n",
        "groupings = np.array(sent_ld_df['Group'].tolist())\n",
        "\n",
        "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "\n",
        "for idx_1, idx_2 in gss.split(idx, groups=groupings):\n",
        "  train_idx = idx_1\n",
        "  dev_idx = idx_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cjkNOxWBuNp",
        "colab_type": "text"
      },
      "source": [
        "Let's save the training and development datasets into tsv files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbXIob9-A_AH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_df = sent_ld_df[['Summary_Sentence', 'Label']].loc[train_idx]\n",
        "dev_data_df = sent_ld_df[['Summary_Sentence', 'Label']].loc[dev_idx]\n",
        "\n",
        "train_data_df.to_csv('./data/Wiki/train.tsv', float_format='%.0f', \\\n",
        "                     encoding='utf-8', header=False, index=False, sep='\\t')\n",
        "\n",
        "dev_data_df.to_csv('./data/Wiki/dev.tsv', float_format='%.0f', \\\n",
        "                   encoding='utf-8', header=False, index=False, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0IxLUArxc_s",
        "colab_type": "text"
      },
      "source": [
        "# Finetuning ALBERT... Finally!\n",
        "\n",
        "It is true when people say that in the field of Data Science, you spend most of the time analyzing and cleaning the data. We probably spent half of the blog post preparing the data for this section. \n",
        "\n",
        "Now it is time for the exciting bit! **We will create an `Albert` class that we will use to generate our sentiments.** There are a couple of **helper functions** that `Albert` will be using. Most of the helper functions are adapted from the [Huggingface github page](https://github.com/huggingface/transformers). If there any tips on how I can do this better, do drop me an email!\n",
        "\n",
        "The helper functions `_create_examples`, `_convert_examples_to_features`, `_read_tsv`, `create_dataset` are primarily used to **convert our training and development datasets into a format** that can be ingested by the Huggingface's model. Do check out this [Huggingface github page](https://github.com/huggingface/transformers/blob/master/src/transformers/data/processors/utils.py) if you are interested in understanding the InputExample and InputFeatures data types.\n",
        "\n",
        "`_plot_cost_history` will be used to **plot the training and development loss/accuracies** to see how how our model is performing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1UTEdyqfubp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _create_examples(lines, set_type, col_num_text, col_num_label):\n",
        "    \"\"\"\n",
        "    Helper function for Albert's preprocess_str method.\n",
        "    Create examples for the training and dev sets\n",
        "\n",
        "    args:\n",
        "    ------\n",
        "        lines: (list) contains the guid, text to be labeled, and the label \n",
        "        set_type: (str) denotes whether the lines are training or dev data\n",
        "                  eg. \"train\", \"dev\"\n",
        "    Return:\n",
        "    ------\n",
        "        examples: (list) contains training/dev examples (InputExample object)\n",
        "                        for sequence classification\n",
        "    \"\"\"\n",
        "\n",
        "    examples = []\n",
        "    for (i, line) in enumerate(lines):\n",
        "        if i == 0:\n",
        "          pass\n",
        "        else:\n",
        "          guid = \"%s-%s\" % (set_type, i)\n",
        "          text_a = line[col_num_text] # To check if this is index 0\n",
        "          label = line[col_num_label]\n",
        "          examples.append(utils.InputExample(guid=guid, text_a=text_a, \\\n",
        "                                             text_b=None, label=label))\n",
        "        \n",
        "    return examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxXotqlIf3Z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _convert_examples_to_features(examples, tokenizer, max_length, task):\n",
        "    \"\"\"\n",
        "    Helper function for Albert's preprocess_str method.\n",
        "    Convert data from examples to features\n",
        "\n",
        "    args:\n",
        "    ------\n",
        "        examples: (list) contains training/dev examples ``InputExample``\n",
        "                  for sequence classification\n",
        "    Return:\n",
        "    ------\n",
        "        features: (list) contains task-specific ``InputFeatures``\n",
        "                  which can be fed to the Albert model.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    label_list = [\"0\",\"1\"]\n",
        "    features = glue_convert_examples_to_features(examples=examples, \\\n",
        "                                                label_list=label_list, \\\n",
        "                                                tokenizer=tokenizer, \\\n",
        "                                                max_length=max_length, task=task)\n",
        "    \n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjLY8afUf6Vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _read_tsv(file_path):\n",
        "    \"\"\"\n",
        "    Helper function for Albert's preprocess_str method.\n",
        "    Reads a tab separated value file.\n",
        "\n",
        "    args:\n",
        "    ------\n",
        "        file_path: (str) path leading to the tab separated tsv file\n",
        "    Return:\n",
        "    ------\n",
        "        list with each element representing a row in the tsv file\n",
        "    \"\"\"\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "        return list(csv.reader(f, delimiter=\"\\t\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts_QZoEVf-MQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _create_dataset(features, buffer_size, batch_size):\n",
        "    \"\"\"\n",
        "    Helper function for Albert's preprocess_str method.\n",
        "    Convert features into ``tf.data.Dataset``.\n",
        "\n",
        "    args:\n",
        "    ------\n",
        "        features: (list) contains task-specific ``InputFeatures`` which can be\n",
        "                  fed to the model.\n",
        "        buffer_size: (int) representing the number of elements from this dataset\n",
        "                    which the new dataset will sample from\n",
        "        batch_size: (int) size of each batch generated from the dataset\n",
        "    Return:\n",
        "    ------\n",
        "        A ``tf.data.Dataset`` containining task specific features\n",
        "    \"\"\"\n",
        "\n",
        "    data_size = len(features)\n",
        "\n",
        "    def gen():\n",
        "        for ex in features:\n",
        "            yield (\n",
        "                {\n",
        "                    \"input_ids\": ex.input_ids,\n",
        "                    \"attention_mask\": ex.attention_mask,\n",
        "                    \"token_type_ids\": ex.token_type_ids,\n",
        "                },\n",
        "                ex.label,\n",
        "            )\n",
        "\n",
        "    train_dataset = tf.data.Dataset.from_generator(\n",
        "        gen,\n",
        "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
        "        (\n",
        "            {\n",
        "                \"input_ids\": tf.TensorShape([None]),\n",
        "                \"attention_mask\": tf.TensorShape([None]),\n",
        "                \"token_type_ids\": tf.TensorShape([None]),\n",
        "            },\n",
        "            tf.TensorShape([]),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    return train_dataset.shuffle(buffer_size).batch(batch_size).repeat(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spmC4y7ZgGQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _plot_cost_history(history):\n",
        "    \"\"\"\n",
        "    Helper function for Albert's fintune method.\n",
        "    Plots a line graph illustrating the loss for each epoch.\n",
        "\n",
        "    args:\n",
        "    ------\n",
        "        history: (tf history object) contains the loss parameters to be charted\n",
        "        epochs: (int) number of epochs. Used as the x-axis of the graph\n",
        "    Return:\n",
        "    ------\n",
        "        A ``tf.data.Dataset`` containining task specific features\n",
        "    \"\"\"\n",
        "\n",
        "    # Get number of epochs\n",
        "    n_epochs = len(history.history['accuracy'])\n",
        "\n",
        "    # Top plot\n",
        "    plt.subplot(2,1,1)\n",
        "    plt.title('Accuracy/Loss')\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xticks(np.arange(n_epochs))\n",
        "\n",
        "    # Bottom plot\n",
        "    plt.subplot(2,1,2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylabel('Loss')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Get number of epochs\n",
        "    n_epochs = len(history.history['accuracy'])\n",
        "    plt.xticks(np.arange(n_epochs))\n",
        "\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.savefig('train_val.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm87oBC4ZP9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Albert:\n",
        "    def __init__(self, **kwargs):\n",
        "\n",
        "        for key, value in kwargs.items():\n",
        "          setattr(self, key, value)\n",
        "\n",
        "        albert4Seq = TFAlbertForSequenceClassification.from_pretrained(self.albert_config, output_attentions=True)\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr)\n",
        "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "        metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "        albert4Seq.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        "\n",
        "        if self.load_weights_path:\n",
        "          albert4Seq.load_weights(self.load_weights_path)\n",
        "          albert4Seq.optimizer.lr.assign(self.lr)\n",
        "        \n",
        "        self.embed = albert4Seq\n",
        "        self.tokenizer = AlbertTokenizer.from_pretrained(self.albert_config)\n",
        "\n",
        "        print('model initiated!') \n",
        "\n",
        "    def preprocess_str(self, train_data_path, dev_data_path):\n",
        "        \"\"\"\n",
        "        Reads and converts training and dev data from a .tsv file into a\n",
        "        tensorflow dataset\n",
        "\n",
        "        args:\n",
        "        ------\n",
        "            train_data_path: (str) path leading to the training .tsv file\n",
        "            dev_data_path: (int) path leading to the dev .tsv file\n",
        "        Return:\n",
        "        ------\n",
        "            train_dataset: (tf.data.Dataset) containining task specific training\n",
        "                          features\n",
        "            dev_dataset: (tf.data.Dataset) containining task specific dev features\n",
        "            train_size: (int) number of training data\n",
        "            dev_size: (int) number of dev data\n",
        "        \"\"\"\n",
        "\n",
        "        train_raw = _read_tsv(train_data_path)\n",
        "        dev_raw = _read_tsv(dev_data_path)\n",
        "\n",
        "        train_size = len(train_raw)\n",
        "        dev_size = len(dev_raw)\n",
        "\n",
        "        train_examples = _create_examples(train_raw,\n",
        "                                          \"train\",\n",
        "                                          self.col_num_text_a,\n",
        "                                          self.col_num_label)\n",
        "        \n",
        "        dev_examples = _create_examples(dev_raw,\n",
        "                                        \"dev\",\n",
        "                                        self.col_num_text_a,\n",
        "                                        self.col_num_label)\n",
        "        \n",
        "        train_features = _convert_examples_to_features(train_examples,\n",
        "                                                        self.tokenizer,\n",
        "                                                        self.max_seq_length,\n",
        "                                                        self.task)\n",
        "        \n",
        "        dev_features = _convert_examples_to_features(dev_examples,\n",
        "                                                      self.tokenizer,\n",
        "                                                      self.max_seq_length,\n",
        "                                                      self.task)\n",
        "        \n",
        "        train_dataset = _create_dataset(train_features,\n",
        "                                        self.buffer_size,\n",
        "                                        self.batch_size)\n",
        "        \n",
        "        dev_dataset = _create_dataset(dev_features,\n",
        "                                      self.buffer_size,\n",
        "                                      self.batch_size)\n",
        "        \n",
        "        return train_dataset, dev_dataset, train_size, dev_size\n",
        "\n",
        "    def finetune(self):\n",
        "        \"\"\"\n",
        "        Finetunes the Albert model\n",
        "        \"\"\"\n",
        "\n",
        "        train_dataset, dev_dataset, self.train_size, \\\n",
        "        self.dev_size = self.preprocess_str(train_data_path=self.train_data_path,\n",
        "                                            dev_data_path=self.dev_data_path)\n",
        "        \n",
        "        print('dataset loaded!')\n",
        "\n",
        "        # Callbacks\n",
        "        reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                      factor=self.reduce_lr_factor,\n",
        "                                      patience=self.lr_patience,\n",
        "                                      min_lr=self.min_lr)\n",
        "\n",
        "        checkpoint = ModelCheckpoint(self.checkpoint_save_path,\n",
        "                                      monitor='val_loss',\n",
        "                                      verbose=1,\n",
        "                                      save_best_only=True,\n",
        "                                      mode='min')\n",
        "\n",
        "        early_stop =  EarlyStopping(monitor='val_loss',\n",
        "                                    patience=self.early_stop_patience,\n",
        "                                    restore_best_weights=True)\n",
        "\n",
        "        # Model\n",
        "        epochs = self.num_epochs\n",
        "        train_steps = self.train_size // self.batch_size\n",
        "        valid_steps = self.dev_size // self.batch_size\n",
        "\n",
        "        albert_history = self.embed.fit(train_dataset, \n",
        "                                        epochs=epochs, \n",
        "                                        steps_per_epoch=train_steps,\n",
        "                                        validation_data=dev_dataset,\n",
        "                                        validation_steps=valid_steps,\n",
        "                                        callbacks=[reduce_lr,\n",
        "                                                  checkpoint,\n",
        "                                                  early_stop])\n",
        "\n",
        "        # Plot loss\n",
        "        _plot_cost_history(albert_history)\n",
        "\n",
        "    def export(self, file_path=''):\n",
        "        \"\"\"\n",
        "        Export finetuned model\n",
        "\n",
        "        args:\n",
        "        ------\n",
        "            file_path: (str) path leading to the directory to save the \n",
        "                      finetuned model\n",
        "        \"\"\"\n",
        "\n",
        "        self.embed.save_weights(file_path)\n",
        "\n",
        "    def restore(self, file_path=''):\n",
        "        \"\"\"\n",
        "        Restore Albert model with finetuned model\n",
        "\n",
        "        args:\n",
        "        ------\n",
        "            file_path: (str) path leading to the directory with finetuned model\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            self.embed.load_weights(file_path)\n",
        "        except Exception as e:\n",
        "            print(str(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDqF_kNgEmms",
        "colab_type": "text"
      },
      "source": [
        "## Finetuning on SQUAD SST-2 Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQscVE2RaluC",
        "colab_type": "text"
      },
      "source": [
        "![](my_icons/geopolitical_mapper/transfer_learning.JPG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou9EYIFNwUVc",
        "colab_type": "text"
      },
      "source": [
        "Huggingface offers pretrained models that need to be finetuned with your own use case. At this point, the Huggingface ALBERT model is not capable of differentiating between positive and negative sentiments. For ALBERT to learn how to differentiate the two types of sentiment, we will need to first **finetune `Albert` using SQUAD's SST-2 dataset**. The SST-2 dataset contains sentences from **movie reviews** and human annotations of their sentiments. Here are two examples adapted from the dataset:\n",
        "\n",
        "* Negative sentiment -  \"contains no wit , only labored gags\"\n",
        "\n",
        "* Positive sentiment - \"are more deeply thought through than in most right-thinking films\"\n",
        "\n",
        "Once, we have trained a model capable of differentiating negative and sentiments by analyzing movie reviews, we will **implement transfer learning to further finetune the model with our own Wikipedia summary dataset**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl_b_sHiIekC",
        "colab_type": "text"
      },
      "source": [
        "To download the SST-2 dataset, we will use Huggingface's `download_and_extract`. You can use the same function to download other SQUAD related datasets that you would like to finetune on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S-6aaMiF6UX",
        "colab_type": "code",
        "outputId": "4a2c2ce8-07fa-419d-aa87-c40877f361ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "TASKS = [\"CoLA\", \"SST\", \"MRPC\", \"QQP\", \"STS\", \"MNLI\", \"SNLI\", \"QNLI\", \"RTE\", \"WNLI\", \"diagnostic\"]\n",
        "TASK2PATH = {\"CoLA\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FCoLA.zip?alt=media&token=46d5e637-3411-4188-bc44-5809b5bfb5f4',\n",
        "             \"SST\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8',\n",
        "             \"MRPC\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2Fmrpc_dev_ids.tsv?alt=media&token=ec5c0836-31d5-48f4-b431-7480817f1adc',\n",
        "             \"QQP\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQQP.zip?alt=media&token=700c6acf-160d-4d89-81d1-de4191d02cb5',\n",
        "             \"STS\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSTS-B.zip?alt=media&token=bddb94a7-8706-4e0d-a694-1109e12273b5',\n",
        "             \"MNLI\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FMNLI.zip?alt=media&token=50329ea1-e339-40e2-809c-10c40afff3ce',\n",
        "             \"SNLI\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSNLI.zip?alt=media&token=4afcfbb2-ff0c-4b2d-a09a-dbf07926f4df',\n",
        "             \"QNLI\": 'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQNLIv2.zip?alt=media&token=6fdcf570-0fc5-4631-8456-9505272d1601',\n",
        "             \"RTE\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FRTE.zip?alt=media&token=5efa7e85-a0bb-4f19-8ea2-9e1840f077fb',\n",
        "             \"WNLI\":'https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FWNLI.zip?alt=media&token=068ad0a0-ded7-4bd7-99a5-5e00222e0faf',\n",
        "             \"diagnostic\":'https://storage.googleapis.com/mtl-sentence-representations.appspot.com/tsvsWithoutLabels%2FAX.tsv?GoogleAccessId=firebase-adminsdk-0khhl@mtl-sentence-representations.iam.gserviceaccount.com&Expires=2498860800&Signature=DuQ2CSPt2Yfre0C%2BiISrVYrIFaZH1Lc7hBVZDD4ZyR7fZYOMNOUGpi8QxBmTNOrNPjR3z1cggo7WXFfrgECP6FBJSsURv8Ybrue8Ypt%2FTPxbuJ0Xc2FhDi%2BarnecCBFO77RSbfuz%2Bs95hRrYhTnByqu3U%2FYZPaj3tZt5QdfpH2IUROY8LiBXoXS46LE%2FgOQc%2FKN%2BA9SoscRDYsnxHfG0IjXGwHN%2Bf88q6hOmAxeNPx6moDulUF6XMUAaXCSFU%2BnRO2RDL9CapWxj%2BDl7syNyHhB7987hZ80B%2FwFkQ3MEs8auvt5XW1%2Bd4aCU7ytgM69r8JDCwibfhZxpaa4gd50QXQ%3D%3D'}\n",
        "\n",
        "\n",
        "def download_and_extract(task, file_path):\n",
        "    \"\"\"\n",
        "    Used to download SQUAD dataset for training.\n",
        "    Credits to Huggingface\n",
        "\n",
        "    args:\n",
        "    ------\n",
        "        task: (str) SQUAD task of interest\n",
        "        file_path: (str) path to save the dataset in\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Downloading and extracting %s...\" % task)\n",
        "    data_file = \"%s.zip\" % task\n",
        "    urllib.request.urlretrieve(TASK2PATH[task], data_file)\n",
        "    with zipfile.ZipFile(data_file) as zip_ref:\n",
        "        zip_ref.extractall(file_path)\n",
        "    os.remove(data_file)\n",
        "    print(\"\\tCompleted!\")\n",
        "\n",
        "\n",
        "  download_and_extract(\"SST\", './data/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading and extracting SST...\n",
            "\tCompleted!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ssa-kPiGF5b-",
        "colab_type": "text"
      },
      "source": [
        "The **data files and hyperparameters** needed to finetune `Albert` on the **SQUAD SST-2 task and our wikipedia summaries are different**. To easily facilitate the different training requirements, we will wrap the data paths and parameters in a **`config` dictionary**. Which will be **used to instantiate** `Albert` before finetuning begins.\n",
        "\n",
        "The config to finetune on SQUAD:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW8uFsGpZ_J7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config_squad = {\n",
        "    \"albert_config\": \"albert-base-v2\",\n",
        "    \"task\": \"sst-2\",\n",
        "    \"max_seq_length\": 128,\n",
        "    \"buffer_size\": 128,\n",
        "    \"batch_size\": 36,\n",
        "    \"test_size\": 0.3,\n",
        "    \"random_state\": 42,\n",
        "    \"load_weights_path\": \"\",\n",
        "    \"lr\": 5e-6,\n",
        "    \"reduce_lr_factor\": 0.1,\n",
        "    \"lr_patience\": 1,\n",
        "    \"early_stop_patience\": 3,\n",
        "    \"num_epochs\": 10,\n",
        "    \"min_lr\": 5e-9,\n",
        "    \"train_data_path\": \"./data/SST-2/train.tsv\",\n",
        "    \"dev_data_path\": \"./data/SST-2/dev.tsv\",\n",
        "    \"col_num_text_a\": 0,\n",
        "    \"col_num_label\": 1,\n",
        "    \"checkpoint_save_path\": \"./model/squad-weights-improvement-{epoch:02d}.ckpt\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj7oNrcVKURk",
        "colab_type": "text"
      },
      "source": [
        "The finetuning logs can be seen below. The **fourth epoch** seems to be our best run with the lowest `val_loss` (0.4706)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkKVb-12E10E",
        "colab_type": "code",
        "outputId": "d1826d64-d715-486c-cdb7-13c9593bb150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        }
      },
      "source": [
        "# albert_squad = Albert(**config_squad)\n",
        "\n",
        "# albert_squad.finetune()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model initiated!\n",
            "dataset loaded!\n",
            "Train for 1870 steps, validate for 24 steps\n",
            "Epoch 1/10\n",
            "1869/1870 [============================>.] - ETA: 0s - loss: 0.5781 - accuracy: 0.6841\n",
            "Epoch 00001: val_loss improved from inf to 0.55461, saving model to ./model/squad-weights-improvement-01.ckpt\n",
            "1870/1870 [==============================] - 1013s 542ms/step - loss: 0.5780 - accuracy: 0.6841 - val_loss: 0.5546 - val_accuracy: 0.7222\n",
            "Epoch 2/10\n",
            "1869/1870 [============================>.] - ETA: 0s - loss: 0.4043 - accuracy: 0.8158\n",
            "Epoch 00002: val_loss improved from 0.55461 to 0.52056, saving model to ./model/squad-weights-improvement-02.ckpt\n",
            "1870/1870 [==============================] - 989s 529ms/step - loss: 0.4043 - accuracy: 0.8158 - val_loss: 0.5206 - val_accuracy: 0.7708\n",
            "Epoch 3/10\n",
            "1869/1870 [============================>.] - ETA: 0s - loss: 0.3226 - accuracy: 0.8628\n",
            "Epoch 00003: val_loss did not improve from 0.52056\n",
            "1870/1870 [==============================] - 990s 530ms/step - loss: 0.3226 - accuracy: 0.8628 - val_loss: 0.5379 - val_accuracy: 0.7801\n",
            "Epoch 4/10\n",
            "1869/1870 [============================>.] - ETA: 0s - loss: 0.2661 - accuracy: 0.8911\n",
            "Epoch 00004: val_loss improved from 0.52056 to 0.47058, saving model to ./model/squad-weights-improvement-04.ckpt\n",
            "1870/1870 [==============================] - 990s 529ms/step - loss: 0.2662 - accuracy: 0.8911 - val_loss: 0.4706 - val_accuracy: 0.8032\n",
            "Epoch 5/10\n",
            "1869/1870 [============================>.] - ETA: 0s - loss: 0.2596 - accuracy: 0.8944\n",
            "Epoch 00005: val_loss did not improve from 0.47058\n",
            "1870/1870 [==============================] - 989s 529ms/step - loss: 0.2596 - accuracy: 0.8944 - val_loss: 0.4746 - val_accuracy: 0.8021\n",
            "Epoch 6/10\n",
            "1869/1870 [============================>.] - ETA: 0s - loss: 0.2532 - accuracy: 0.8974\n",
            "Epoch 00006: val_loss did not improve from 0.47058\n",
            "1870/1870 [==============================] - 989s 529ms/step - loss: 0.2533 - accuracy: 0.8973 - val_loss: 0.4724 - val_accuracy: 0.8067\n",
            "Epoch 7/10\n",
            "1869/1870 [============================>.] - ETA: 0s - loss: 0.2526 - accuracy: 0.8976\n",
            "Epoch 00007: val_loss did not improve from 0.47058\n",
            "1870/1870 [==============================] - 989s 529ms/step - loss: 0.2526 - accuracy: 0.8976 - val_loss: 0.4764 - val_accuracy: 0.8044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa8AAAEYCAYAAADrpHnMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmbWHJeXmZk1x+VlZmbN+QVb8pdEBH4fQgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxbbxrm8Z_fd",
        "colab_type": "text"
      },
      "source": [
        "## Finetune using our labeled dataset\n",
        "\n",
        "Ok we have finetuned `Albert` to pick out the positive and negative sentiments movie reviews. Finally, we will finetune `Albert` for our use case using the following configurations. The **eighth epoch** gave the best run with the lowest loss (0.4546)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmMkUKPlaEUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config_summaries = {\n",
        "    \"albert_config\": \"albert-base-v2\",\n",
        "    \"task\": \"sst-2\",\n",
        "    \"max_seq_length\": 128,\n",
        "    \"buffer_size\": 128,\n",
        "    \"batch_size\": 36,\n",
        "    \"test_size\": 0.3,\n",
        "    \"random_state\": 42,\n",
        "    \"load_weights_path\": \"./model/squad-weights-improvement-04.ckpt\",\n",
        "    \"lr\": 5e-5,\n",
        "    \"reduce_lr_factor\": 0.1,\n",
        "    \"lr_patience\": 2,\n",
        "    \"early_stop_patience\": 5,\n",
        "    \"num_epochs\": 20,\n",
        "    \"min_lr\": 5e-9,\n",
        "    \"train_data_path\": \"./data/Wiki/train.tsv\",\n",
        "    \"dev_data_path\": \"./data/Wiki/dev.tsv\",\n",
        "    \"col_num_text_a\": 0,\n",
        "    \"col_num_label\": 1,\n",
        "    \"checkpoint_save_path\": \"./model/summary-weights-improvement-{epoch:02d}.ckpt\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POcr9TPN-dZc",
        "colab_type": "code",
        "outputId": "9c0638b0-8f16-4e77-99a8-2dcda5f7ed50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# albert_summaries = Albert(**config_summaries)\n",
        "\n",
        "# albert_summaries.finetune()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model initiated!\n",
            "dataset loaded!\n",
            "Train for 10 steps, validate for 3 steps\n",
            "Epoch 1/20\n",
            " 9/10 [==========================>...] - ETA: 2s - loss: 0.6752 - accuracy: 0.7068\n",
            "Epoch 00001: val_loss improved from inf to 0.70040, saving model to ./model/summary-weights-improvement-01.ckpt\n",
            "10/10 [==============================] - 30s 3s/step - loss: 0.6479 - accuracy: 0.7306 - val_loss: 0.7004 - val_accuracy: 0.6204\n",
            "Epoch 2/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5817 - accuracy: 0.7081\n",
            "Epoch 00002: val_loss improved from 0.70040 to 0.57846, saving model to ./model/summary-weights-improvement-02.ckpt\n",
            "10/10 [==============================] - 7s 661ms/step - loss: 0.5813 - accuracy: 0.7095 - val_loss: 0.5785 - val_accuracy: 0.7778\n",
            "Epoch 3/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3281 - accuracy: 0.8975\n",
            "Epoch 00003: val_loss did not improve from 0.57846\n",
            "10/10 [==============================] - 6s 600ms/step - loss: 0.3277 - accuracy: 0.8883 - val_loss: 0.9524 - val_accuracy: 0.6574\n",
            "Epoch 4/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.2239 - accuracy: 0.9317\n",
            "Epoch 00004: val_loss did not improve from 0.57846\n",
            "10/10 [==============================] - 6s 607ms/step - loss: 0.2173 - accuracy: 0.9330 - val_loss: 0.5976 - val_accuracy: 0.7593\n",
            "Epoch 5/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0883 - accuracy: 0.9720\n",
            "Epoch 00005: val_loss improved from 0.57846 to 0.54417, saving model to ./model/summary-weights-improvement-05.ckpt\n",
            "10/10 [==============================] - 7s 652ms/step - loss: 0.0857 - accuracy: 0.9749 - val_loss: 0.5442 - val_accuracy: 0.8056\n",
            "Epoch 6/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0800 - accuracy: 0.9752\n",
            "Epoch 00006: val_loss improved from 0.54417 to 0.49869, saving model to ./model/summary-weights-improvement-06.ckpt\n",
            "10/10 [==============================] - 7s 693ms/step - loss: 0.0787 - accuracy: 0.9749 - val_loss: 0.4987 - val_accuracy: 0.7963\n",
            "Epoch 7/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0740 - accuracy: 0.9814\n",
            "Epoch 00007: val_loss did not improve from 0.49869\n",
            "10/10 [==============================] - 6s 604ms/step - loss: 0.0701 - accuracy: 0.9832 - val_loss: 0.5500 - val_accuracy: 0.7593\n",
            "Epoch 8/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0639 - accuracy: 0.9783\n",
            "Epoch 00008: val_loss improved from 0.49869 to 0.45457, saving model to ./model/summary-weights-improvement-08.ckpt\n",
            "10/10 [==============================] - 7s 678ms/step - loss: 0.0592 - accuracy: 0.9804 - val_loss: 0.4546 - val_accuracy: 0.8148\n",
            "Epoch 9/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0410 - accuracy: 0.9876\n",
            "Epoch 00009: val_loss did not improve from 0.45457\n",
            "10/10 [==============================] - 6s 599ms/step - loss: 0.0380 - accuracy: 0.9888 - val_loss: 0.5704 - val_accuracy: 0.7778\n",
            "Epoch 10/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0323 - accuracy: 0.9876\n",
            "Epoch 00010: val_loss did not improve from 0.45457\n",
            "10/10 [==============================] - 6s 599ms/step - loss: 0.0301 - accuracy: 0.9888 - val_loss: 0.5205 - val_accuracy: 0.8056\n",
            "Epoch 11/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0259 - accuracy: 0.9907\n",
            "Epoch 00011: val_loss did not improve from 0.45457\n",
            "10/10 [==============================] - 6s 588ms/step - loss: 0.0248 - accuracy: 0.9916 - val_loss: 0.5801 - val_accuracy: 0.7778\n",
            "Epoch 12/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0183 - accuracy: 0.9969\n",
            "Epoch 00012: val_loss did not improve from 0.45457\n",
            "10/10 [==============================] - 6s 597ms/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 0.5456 - val_accuracy: 0.7870\n",
            "Epoch 13/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0170 - accuracy: 0.9969\n",
            "Epoch 00013: val_loss did not improve from 0.45457\n",
            "10/10 [==============================] - 6s 595ms/step - loss: 0.0181 - accuracy: 0.9972 - val_loss: 0.5932 - val_accuracy: 0.7778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa8AAAEYCAYAAADrpHnMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncZym4/8BXYIiDlC7PicAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX9_6reqxc3q",
        "colab_type": "text"
      },
      "source": [
        "# Predict Sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C0MWmdKbqn6",
        "colab_type": "text"
      },
      "source": [
        "![](my_icons/geopolitical_mapper/crystal_ball.JPG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz0a0OCeNLZU",
        "colab_type": "text"
      },
      "source": [
        "With the model finetuned with our labeled dataset, we can now use it to come up with sentiment predictions. **The sentences need to be encoded** before feeding it into the model to obtain the logits `logit = albert_summaries.embed(encoded_s)[0]`. We will then place the logits through a **softmax function** `_get_proba` to obtain the probabilities that the sentiments are negative or positive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8mZzSmRKXg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _get_proba(logit):\n",
        "    \"\"\"\n",
        "    Helper function for get_predictions_probas\n",
        "    Computes softmax values based on logit\n",
        "\n",
        "    args:\n",
        "    ------\n",
        "        logit: (float) logit output of finetuned ALBERT model\n",
        "    Return:\n",
        "    ------\n",
        "        softmax values representing the sentiment probabilities\n",
        "    \"\"\"\n",
        "\n",
        "    return np.exp(logit) / np.sum(np.exp(logit), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OizXoMdOwZxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predictions_probas(summaries, config, weights_path):\n",
        "    \"\"\"\n",
        "    Returns the sentiment probabilities (positive or negative sentiments)\n",
        "    for the wiki summary sentences\n",
        "\n",
        "    args:\n",
        "    ------\n",
        "        summaries: (list) wiki summary sentences that require sentiment predictions\n",
        "        config: (dict) chosen configuration for the ALBERT model\n",
        "        weights_path: (str) path leading to the weights of the finetuned\n",
        "                      ALBERT model\n",
        "    Return:\n",
        "    ------\n",
        "        sentiment_preds: (list) sentiment predictions for the wiki summary sentences\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    albert_summaries = Albert(**config)\n",
        "    albert_summaries.restore(weights_path)\n",
        "\n",
        "    sentiment_probas = []\n",
        "    for i, s in enumerate(summaries):\n",
        "\n",
        "      encoded_s = albert_summaries.tokenizer.encode_plus(s,\n",
        "                                                        text_pair=None,\n",
        "                                                        max_length=albert_summaries.max_seq_length,\n",
        "                                                        pad_to_max_length=True,\n",
        "                                                        add_special_tokens=True,\n",
        "                                                        return_tensors=\"tf\")\n",
        "    \n",
        "      logit = albert_summaries.embed(encoded_s)[0]\n",
        "      pred = _get_proba(logit)\n",
        "      sentiment_probas.append(pred[:,1][0])\n",
        "\n",
        "    return sentiment_probas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otw7QmhUvsoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "sent_ld_df = pd.read_csv('./data/Wiki/sent_ld.csv')\n",
        "sent_ul_df = pd.read_csv('./data/Wiki/sent_ul.csv')\n",
        "\n",
        "sent_all_df = pd.concat([sent_ld_df, sent_ul_df], axis=0)\n",
        "\n",
        "summaries = sent_all_df['Summary_Sentence'].tolist()\n",
        "\n",
        "sentiment_probas = get_predictions_probas(summaries, config_summaries,\n",
        "                                          './model/summary-weights-improvement-08.ckpt')\n",
        "\n",
        "sent_all_df['Predictions_Probas'] = sentiment_probas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crpNT2MfRnSG",
        "colab_type": "text"
      },
      "source": [
        "And here we have the sentiment probabilities for the sentences! Sentences with probabilities that are **closer to 1** are considered to have **positive sentiments**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJHN6Jv-qrlX",
        "colab_type": "code",
        "outputId": "b635d3ce-4893-4ef7-d039-7cfb2ec1364a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "sent_all_df[['Country_Pair', 'Label', 'Summary_Sentence', 'Predictions_Probas']].head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country_Pair</th>\n",
              "      <th>Label</th>\n",
              "      <th>Summary_Sentence</th>\n",
              "      <th>Predictions_Probas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>China_Indonesia</td>\n",
              "      <td>1.0</td>\n",
              "      <td>The relations between two nations have been on...</td>\n",
              "      <td>0.279244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>China_Indonesia</td>\n",
              "      <td>0.0</td>\n",
              "      <td>However, the diplomatic relationship between t...</td>\n",
              "      <td>0.052571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>China_Indonesia</td>\n",
              "      <td>1.0</td>\n",
              "      <td>China has an embassy in Jakarta and consulates...</td>\n",
              "      <td>0.990907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>China_Indonesia</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Both countries are among the largest nations i...</td>\n",
              "      <td>0.990101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>China_Indonesia</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Both nations are the members of APEC and G-20 ...</td>\n",
              "      <td>0.985640</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Country_Pair  ...  Predictions_Probas\n",
              "0  China_Indonesia  ...            0.279244\n",
              "1  China_Indonesia  ...            0.052571\n",
              "2  China_Indonesia  ...            0.990907\n",
              "3  China_Indonesia  ...            0.990101\n",
              "4  China_Indonesia  ...            0.985640\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlW9h6UxSu8a",
        "colab_type": "text"
      },
      "source": [
        "# How did we do? On to the results!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcllZ-hLb7Dv",
        "colab_type": "text"
      },
      "source": [
        "![](my_icons/geopolitical_mapper/excited_baby.JPG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4AM43mDRzHo",
        "colab_type": "text"
      },
      "source": [
        "To be honest, I do not know how the results will turn out at this point given that the dataset that we were using was self-generated and manually labeled. On a positive note, it appears that the model was able to predict some of the sentiments correctly. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuc7zteHUGIq",
        "colab_type": "text"
      },
      "source": [
        "### Correctly classified relationships"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQGJiS28UIM6",
        "colab_type": "code",
        "outputId": "dc0aca85-5e33-42d8-eb5e-02c7d6543154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "# Sentences\n",
        "print(sent_all_df[sent_all_df['Country_Pair'] == 'China_Singapore']['Summary_Sentence'].tolist())\n",
        "\n",
        "# Sentiment probabilities\n",
        "sent_all_df[sent_all_df['Country_Pair'] == 'China_Singapore']['Predictions_Probas'].tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"People's Republic of China – Singapore relations officially started on 3 October 1990.\", 'Diplomatic missions were established in the early 1990s based on trade and the warming of ties from other ASEAN countries towards mainland China.', 'Singapore and China have maintained a long-standing and greatly prioritised close relationship, and partly because of the latter\\'s growing influence and essentiality in the Asia-Pacific region, specifying that \"its common interest with China is far greater than any differences\".', \"Furthermore, Singapore has positioned itself as a strong supporter for China's constructive engagement and peaceful development in the region.\", \"It has engaged co-operation with other ASEAN members and China to strengthen regional security and fight terrorism, while participating in the organisation's first maritime exercise with the latter.\", \"While relationship between the two countries stand strong, differences were experienced during numerous high-profile events, including Singapore's stance against China regarding the South China Sea dispute, Singapore's support for the United States' military presence and alliance system in Asia and the seizing of SAF vehicles by Hong Kong authorities in November 2016.Despite the disputes, Singapore and Beijing have consistently affirm their unwavering close relationship and bilateral ties, deepening their co-operation in numerous areas, including defence, economy, culture and education, as well as One Belt One Road Initiative.\", \"Singapore has also vowed to fully support and promote China's position in ASEAN, while managing the differences between the Chinese state and the organisation.\"]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9891862273216248,\n",
              " 0.98930823802948,\n",
              " 0.9773917198181152,\n",
              " 0.990622878074646,\n",
              " 0.9888237714767456,\n",
              " 0.9899033308029175,\n",
              " 0.9854150414466858]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tegi9fgm0G10",
        "colab_type": "code",
        "outputId": "7c6397f9-ff96-410e-961b-b45f859899de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# Sentences\n",
        "print(sent_all_df[sent_all_df['Country_Pair'] == 'Russia_United States']['Summary_Sentence'].tolist()[0:4])\n",
        "\n",
        "# Sentiment probabilities\n",
        "sent_all_df[sent_all_df['Country_Pair'] == 'Russia_United States']['Predictions_Probas'].tolist()[0:4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The United States and Russia maintain diplomatic and trade relations.', 'The relationship was generally warm under the Russian President Boris Yeltsin (1991–99) until the NATO bombing of the Federal Republic of Yugoslavia in the spring of 1999, and has since deteriorated significantly.', \"In 2014, relations greatly deteriorated further due to the crisis in Ukraine, Russia's annexation of Crimea in 2014, differences regarding Russian military intervention in the Syrian Civil War, and from the end of 2016 over Russia's alleged interference in the 2016 U.S. elections.\", 'Mutual sanctions imposed in 2014 remain in place.']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9242598414421082,\n",
              " 0.9835892915725708,\n",
              " 0.01635131798684597,\n",
              " 0.013922506012022495]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAljSbjLUJVG",
        "colab_type": "text"
      },
      "source": [
        "### Incorrectly classified relationships"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-YoSLIp4maf",
        "colab_type": "code",
        "outputId": "48c830e0-2c22-499c-a383-0f659a41bd96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# Sentences\n",
        "print(sent_all_df[sent_all_df['Country_Pair'] == 'China_United States']['Summary_Sentence'].tail(5).tolist())\n",
        "\n",
        "# Sentiment probabilities\n",
        "sent_all_df[sent_all_df['Country_Pair'] == 'China_United States']['Predictions_Probas'].tail(5).tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Despite tensions during his term, the Chinese population's favorability of the U.S. stood at 51% in Obama's last year of 2016, only to dip during the Trump Administration.\", 'The relations deteriorated sharply under President Donald Trump, whose administration launched a trade war against China, banned US companies from selling equipment to Huawei, increased visa restrictions on Chinese nationality students and scholars and designated China as a \"currency manipulator\".', 'During the Trump administration, and especially since the US-China trade war began, political observers have started to warn that a new cold war is emerging.', 'Michael D. Swaine warned in 2019, \"The often positive and optimistic forces, interests, and beliefs that sustained bilateral ties for decades are giving way to undue pessimism, hostility, and a zero-sum mindset in almost every area of engagement.\"', 'However by 2020, the two countries have started to take steps in order to repair the relations; U.S. lifted its currency manipulator designation on China in 13 January 2020, and both sides signed the US–China Phase One trade deal in 15 January.']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.17708182334899902,\n",
              " 0.7658159732818604,\n",
              " 0.10857371240854263,\n",
              " 0.7851555347442627,\n",
              " 0.1416555643081665]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8vmZhkmUOMu",
        "colab_type": "text"
      },
      "source": [
        "Our model can definitely do better! It will be great if we could have more training data if time permits!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scHk6Z7FUuvh",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing our predictions!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgSBd2uKcwpx",
        "colab_type": "text"
      },
      "source": [
        "![](my_icons/geopolitical_mapper/visualization.JPG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "907D8dsRVXJe",
        "colab_type": "text"
      },
      "source": [
        "Our aim in this section is for us to visualize the sentiments on a world map plot. We will allow a user to select a country to focus on. And the sentiments of its relationships with other countries will be displayed on the plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGLlF-BXWBSK",
        "colab_type": "text"
      },
      "source": [
        "By default we will **allow the user to choose a country from column `Country_A`**. Currently our dataframe of predictions comprises of **one-directional relationships**. For example, if United States - China was represented in the dataframe, the China - United States relationship would be missing. Let's **stack** the dataframe we have currently, with another dataframe where the names in columns `Country_A` and `Country_B` are swapped."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Rvy0IRDbsfj",
        "colab_type": "text"
      },
      "source": [
        "### Creating a stacked dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1adEgyOH5kYa",
        "colab_type": "text"
      },
      "source": [
        "Great! Now all of our relationships are represented!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNVNFQgUbsGJ",
        "colab_type": "code",
        "outputId": "d4f48147-c805-495c-f8af-3c7c2e829ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "sent_all_swap_df = sent_all_df.copy()\n",
        "sent_all_swap_df['Country_A'] = sent_all_df['Country_B']\n",
        "sent_all_swap_df['Country_B'] = sent_all_df['Country_A']\n",
        "\n",
        "sent_all_stack_df = pd.concat([sent_all_df, sent_all_swap_df], axis=0)\n",
        "sent_all_stack_df.sort_values(by='Country_A', ascending=False)\n",
        "\n",
        "sent_all_stack_df[sent_all_stack_df['Country_Pair'].str.contains('China_United States')]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country_A</th>\n",
              "      <th>Country_B</th>\n",
              "      <th>Country_Pair</th>\n",
              "      <th>Label</th>\n",
              "      <th>Summary_Sentence</th>\n",
              "      <th>Predictions_Probas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2436</th>\n",
              "      <td>China</td>\n",
              "      <td>United States</td>\n",
              "      <td>China_United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>China–United States relations (simplified Chin...</td>\n",
              "      <td>0.651927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2437</th>\n",
              "      <td>China</td>\n",
              "      <td>United States</td>\n",
              "      <td>China_United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The history of the relationship can be traced ...</td>\n",
              "      <td>0.987907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2438</th>\n",
              "      <td>China</td>\n",
              "      <td>United States</td>\n",
              "      <td>China_United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The relationship between the two countries hav...</td>\n",
              "      <td>0.985974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2439</th>\n",
              "      <td>China</td>\n",
              "      <td>United States</td>\n",
              "      <td>China_United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Both countries used to have an extremely exten...</td>\n",
              "      <td>0.517934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2440</th>\n",
              "      <td>China</td>\n",
              "      <td>United States</td>\n",
              "      <td>China_United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It is a relationship of economic cooperation, ...</td>\n",
              "      <td>0.399313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6048</th>\n",
              "      <td>United States</td>\n",
              "      <td>China</td>\n",
              "      <td>China_United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Despite tensions during his term, the Chinese ...</td>\n",
              "      <td>0.177082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6049</th>\n",
              "      <td>United States</td>\n",
              "      <td>China</td>\n",
              "      <td>China_United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The relations deteriorated sharply under Presi...</td>\n",
              "      <td>0.765816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6050</th>\n",
              "      <td>United States</td>\n",
              "      <td>China</td>\n",
              "      <td>China_United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>During the Trump administration, and especiall...</td>\n",
              "      <td>0.108574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6051</th>\n",
              "      <td>United States</td>\n",
              "      <td>China</td>\n",
              "      <td>China_United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Michael D. Swaine warned in 2019, \"The often p...</td>\n",
              "      <td>0.785156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6052</th>\n",
              "      <td>United States</td>\n",
              "      <td>China</td>\n",
              "      <td>China_United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>However by 2020, the two countries have starte...</td>\n",
              "      <td>0.141656</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Country_A  ... Predictions_Probas\n",
              "2436          China  ...           0.651927\n",
              "2437          China  ...           0.987907\n",
              "2438          China  ...           0.985974\n",
              "2439          China  ...           0.517934\n",
              "2440          China  ...           0.399313\n",
              "...             ...  ...                ...\n",
              "6048  United States  ...           0.177082\n",
              "6049  United States  ...           0.765816\n",
              "6050  United States  ...           0.108574\n",
              "6051  United States  ...           0.785156\n",
              "6052  United States  ...           0.141656\n",
              "\n",
              "[100 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDRbHA5154FG",
        "colab_type": "text"
      },
      "source": [
        "### Calculating the average sentiment score\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al8jDARD5-Pb",
        "colab_type": "text"
      },
      "source": [
        "As we have calculated the sentiment score at a sentence level,we will use pandas' `groupby` to **average the sentiment score** for each country pair."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwbRNc6Dzm4c",
        "colab_type": "code",
        "outputId": "0bb52ae5-5515-47e0-c2ca-ee2134c713c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "sent_all_stack_df.groupby('Country_Pair').mean()['Predictions_Probas']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Country_Pair\n",
              "Abkhazia_Nauru           0.938478\n",
              "Abkhazia_Nicaragua       0.757214\n",
              "Abkhazia_Tuvalu          0.961020\n",
              "Abkhazia_Vanuatu         0.523380\n",
              "Afghanistan_China        0.813562\n",
              "                           ...   \n",
              "United States_Vietnam    0.910205\n",
              "United States_Yemen      0.086554\n",
              "United States_Zambia     0.740769\n",
              "Yemen_European Union     0.984979\n",
              "Zambia_Zimbabwe          0.635722\n",
              "Name: Predictions_Probas, Length: 1171, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jAzcgQMxcrG",
        "colab_type": "text"
      },
      "source": [
        "### Retrieving the ISO code for each country"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXMLcLU87xOH",
        "colab_type": "text"
      },
      "source": [
        "Plotly, the visualization package that we will be using, **identifies each country's location on the world map by using the ISO code.** We can easily retrieve the ISO codes in the form of a txt file from the web. However, once again, the names of the countries used in the ISO codes txt file might be different from what we have in the dataframe. \n",
        "\n",
        "Fret not! `get_std_names` is here to save the day. We will map the names of the countries in the txt file to obtain its standardized `std` names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkhfZRxdafzW",
        "colab_type": "code",
        "outputId": "c4ec2867-c11c-4c7e-80d8-9101e5d8b4f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "country_ISO_raw_df = pd.read_csv('./data/Wiki/country_ISO.txt', sep=\"  \",\n",
        "                                 header=None, names=['ISO_Code', 'Country'])\n",
        "\n",
        "country_ISO_df = get_std_names(country_ISO_raw_df,\n",
        "                               'Country', alt_names_to_countries)\n",
        "\n",
        "country_ISO_df.sort_values(by=['Country']).head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ISO_Code</th>\n",
              "      <th>Country</th>\n",
              "      <th>Country_Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AFG</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>afghanistan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ALB</td>\n",
              "      <td>Albania</td>\n",
              "      <td>albania</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>DZA</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>algeria</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ASM</td>\n",
              "      <td>American Samoa</td>\n",
              "      <td>american_samoa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AND</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>andorra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AGO</td>\n",
              "      <td>Angola</td>\n",
              "      <td>angola</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AIA</td>\n",
              "      <td>Anguilla</td>\n",
              "      <td>anguilla</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ATA</td>\n",
              "      <td>Antarctica</td>\n",
              "      <td>antarctica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ATG</td>\n",
              "      <td>Antigua and Barbuda</td>\n",
              "      <td>antigua_and_barbuda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ARG</td>\n",
              "      <td>Argentina</td>\n",
              "      <td>argentina</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ISO_Code              Country          Country_Std\n",
              "1       AFG          Afghanistan          afghanistan\n",
              "5       ALB              Albania              albania\n",
              "64      DZA              Algeria              algeria\n",
              "10      ASM       American Samoa       american_samoa\n",
              "6       AND              Andorra              andorra\n",
              "2       AGO               Angola               angola\n",
              "3       AIA             Anguilla             anguilla\n",
              "11      ATA           Antarctica           antarctica\n",
              "13      ATG  Antigua and Barbuda  antigua_and_barbuda\n",
              "8       ARG            Argentina            argentina"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq8S6Rwtayvv",
        "colab_type": "text"
      },
      "source": [
        "We will convert the dataframe into a dictionary for faster mappings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeevV2KsbLmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "country_to_ISO = {k:v for k,v in zip(country_ISO_df['Country_Std'], \\\n",
        "                                     country_ISO_df['ISO_Code'])}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMHdddhWbOkl",
        "colab_type": "text"
      },
      "source": [
        "Let's create an additional column in our `sent_all_stack_df` to populate the ISO codes of the countries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTMreCBmzvIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ISO(country):\n",
        "  try:\n",
        "    ISO = country_to_ISO[country]\n",
        "  except:\n",
        "    ISO = 'Not Available'\n",
        "\n",
        "  return ISO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sUFj1GZbNZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_all_stack_df = get_std_names(sent_all_stack_df, 'Country_A', \\\n",
        "                                  alt_names_to_countries)\n",
        "\n",
        "sent_all_stack_df = get_std_names(sent_all_stack_df, 'Country_B', \\\n",
        "                                  alt_names_to_countries)\n",
        "\n",
        "sent_all_stack_df['country_A_ISO'] = sent_all_stack_df['Country_A_Std'].apply(get_ISO)\n",
        "sent_all_stack_df['country_B_ISO'] = sent_all_stack_df['Country_B_Std'].apply(get_ISO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNXNGTjocKaV",
        "colab_type": "text"
      },
      "source": [
        "We will exclude countries with no ISO codes for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oha0-xPtcKLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_all_stack_avail_df = sent_all_stack_df[sent_all_stack_df['country_A_ISO'] != 'Not Available']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI2Dtfvf0BLE",
        "colab_type": "text"
      },
      "source": [
        "# Time to visualize the sentiments!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu-_XPcqdT2L",
        "colab_type": "text"
      },
      "source": [
        "![](my_icons/geopolitical_mapper/finally_over_obama.JPG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7MAlM8xcUgU",
        "colab_type": "text"
      },
      "source": [
        "Here are countries that we can choose from."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WW99o2DsWOJ",
        "colab_type": "code",
        "outputId": "cac08959-c524-4174-ba3e-4922578dc774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        }
      },
      "source": [
        "np.sort(sent_all_stack_avail_df['Country_A_Std'].unique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['afghanistan', 'albania', 'algeria', 'andorra', 'angola',\n",
              "       'antigua_and_barbuda', 'argentina', 'armenia', 'australia',\n",
              "       'austria', 'azerbaijan', 'bahamas', 'bahrain', 'bangladesh',\n",
              "       'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bhutan',\n",
              "       'bolivia', 'bosnia_and_herzegovina', 'botswana', 'brazil',\n",
              "       'bulgaria', 'burkina_faso', 'burundi', 'cambodia', 'cameroon',\n",
              "       'canada', 'cape_verde', 'central_african_republic', 'chad',\n",
              "       'chile', 'china', 'colombia', 'comoros', 'costa_rica', 'croatia',\n",
              "       'cuba', 'cyprus', 'czech_republic', 'denmark', 'djibouti',\n",
              "       'dominica', 'dominican_republic', 'east_timor', 'ecuador', 'egypt',\n",
              "       'el_salvador', 'equatorial_guinea', 'eritrea', 'estonia',\n",
              "       'eswatini', 'ethiopia', 'fiji', 'finland', 'france', 'gabon',\n",
              "       'gambia', 'georgia', 'germany', 'ghana', 'greece', 'grenada',\n",
              "       'guatemala', 'guinea-bissau', 'guyana', 'haiti', 'holy_see',\n",
              "       'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran',\n",
              "       'iraq', 'ireland', 'israel', 'italy', 'ivory_coast', 'jamaica',\n",
              "       'japan', 'jordan', 'kazakhstan', 'kenya', 'kiribati', 'kuwait',\n",
              "       'kyrgyzstan', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya',\n",
              "       'liechtenstein', 'lithuania', 'luxembourg', 'madagascar', 'malawi',\n",
              "       'malaysia', 'maldives', 'mali', 'malta', 'marshall_islands',\n",
              "       'mauritania', 'mauritius', 'mexico', 'moldova', 'monaco',\n",
              "       'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar',\n",
              "       'namibia', 'nauru', 'nepal', 'netherlands', 'new_zealand',\n",
              "       'nicaragua', 'niger', 'nigeria', 'north_macedonia', 'norway',\n",
              "       'oman', 'pakistan', 'palau', 'panama', 'papua_new_guinea',\n",
              "       'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar',\n",
              "       'republic_of_congo', 'romania', 'russia', 'rwanda', 'saint_lucia',\n",
              "       'saint_vincent_and_grenadines', 'samoa', 'san_marino',\n",
              "       'saudi_arabia', 'senegal', 'serbia', 'seychelles', 'sierra_leone',\n",
              "       'singapore', 'slovakia', 'slovenia', 'solomon_islands', 'somalia',\n",
              "       'south_africa', 'south_korea', 'south_sudan', 'spain', 'sri_lanka',\n",
              "       'sudan', 'suriname', 'sweden', 'switzerland', 'taiwan',\n",
              "       'tajikistan', 'tanzania', 'thailand', 'togo', 'tonga',\n",
              "       'trinidad_and_tobago', 'tunisia', 'turkey', 'turkmenistan',\n",
              "       'tuvalu', 'uganda', 'ukraine', 'united_arab_emirates',\n",
              "       'united_kingdom', 'united_states', 'uruguay', 'uzbekistan',\n",
              "       'vanuatu', 'venezuela', 'vietnam', 'yemen', 'zambia', 'zimbabwe'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgm98dj9cdjw",
        "colab_type": "text"
      },
      "source": [
        "For illustration purposes, let's select **\"united_states\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7pRJ0g9cbKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "country = \"united_states\"\n",
        "sent_country_df = sent_all_stack_avail_df[sent_all_stack_avail_df['Country_A_Std'] == country]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtFvPHL-cigx",
        "colab_type": "text"
      },
      "source": [
        "With the help of Plotly, we are able to illustrate the sentiments on a world map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8EoerAwcjKK",
        "colab_type": "code",
        "outputId": "bf63b9e5-38d7-4110-a5a8-c72cb209dab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        }
      },
      "source": [
        "# https://plot.ly/python/bubble-maps/\n",
        "\n",
        "import plotly.express as px\n",
        "fig = px.scatter_geo(sent_country_df,\n",
        "                     locations=\"country_B_ISO\",\n",
        "                     color=\"Predictions_Probas\",\n",
        "                     hover_name=\"Country_B_Std\",\n",
        "                     projection=\"natural earth\")\n",
        "\n",
        "# To show smaller countries\n",
        "fig.update_layout({\n",
        "    'geo': {\n",
        "        'resolution': 50\n",
        "    }\n",
        "})\n",
        "\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"89bb0340-092e-4b1b-a377-dfe9270224ae\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"89bb0340-092e-4b1b-a377-dfe9270224ae\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '89bb0340-092e-4b1b-a377-dfe9270224ae',\n",
              "                        [{\"geo\": \"geo\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"<b>%{hovertext}</b><br><br>country_B_ISO=%{location}<br>Predictions_Probas=%{marker.color}\", \"hovertext\": [\"uzbekistan\", \"uzbekistan\", \"uzbekistan\", \"uzbekistan\", \"uzbekistan\", \"uzbekistan\", \"uzbekistan\", \"uzbekistan\", \"yemen\", \"yemen\", \"yemen\", \"vanuatu\", \"vanuatu\", \"vanuatu\", \"zambia\", \"zambia\", \"zambia\", \"zambia\", \"zambia\", \"zambia\", \"zambia\", \"zambia\", \"zambia\", \"vietnam\", \"vietnam\", \"vietnam\", \"vietnam\", \"vietnam\", \"vietnam\", \"vietnam\", \"vietnam\", \"vietnam\", \"vietnam\", \"venezuela\", \"venezuela\", \"venezuela\", \"venezuela\", \"venezuela\", \"venezuela\", \"venezuela\", \"venezuela\", \"venezuela\", \"venezuela\", \"venezuela\", \"uruguay\", \"russia\", \"russia\", \"russia\", \"russia\", \"iraq\", \"iraq\", \"iraq\", \"iraq\", \"iraq\", \"iraq\", \"iceland\", \"libya\", \"libya\", \"libya\", \"libya\", \"libya\", \"libya\", \"libya\", \"libya\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"slovakia\", \"senegal\", \"senegal\", \"montenegro\", \"montenegro\", \"kuwait\", \"kuwait\", \"burkina_faso\", \"burkina_faso\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"grenada\", \"grenada\", \"philippines\", \"philippines\", \"philippines\", \"philippines\", \"philippines\", \"philippines\", \"france\", \"france\", \"france\", \"france\", \"france\", \"france\", \"france\", \"france\", \"central_african_republic\", \"nigeria\", \"nigeria\", \"nigeria\", \"nigeria\", \"nigeria\", \"nigeria\", \"nigeria\", \"nigeria\", \"nigeria\", \"nigeria\", \"nigeria\", \"nigeria\", \"nigeria\", \"nigeria\", \"nigeria\", \"nigeria\", \"laos\", \"laos\", \"azerbaijan\", \"hungary\", \"singapore\", \"singapore\", \"niger\", \"tonga\", \"tonga\", \"tonga\", \"tonga\", \"tonga\", \"tonga\", \"tonga\", \"tonga\", \"tonga\", \"tonga\", \"tonga\", \"tonga\", \"tonga\", \"tonga\", \"tonga\", \"south_africa\", \"south_africa\", \"south_africa\", \"south_africa\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"bulgaria\", \"bulgaria\", \"lebanon\", \"lebanon\", \"lebanon\", \"lebanon\", \"jordan\", \"jordan\", \"serbia\", \"serbia\", \"serbia\", \"serbia\", \"serbia\", \"serbia\", \"serbia\", \"serbia\", \"serbia\", \"serbia\", \"serbia\", \"serbia\", \"serbia\", \"serbia\", \"serbia\", \"serbia\", \"guinea-bissau\", \"malaysia\", \"malaysia\", \"malaysia\", \"malaysia\", \"malaysia\", \"malaysia\", \"malaysia\", \"malaysia\", \"malaysia\", \"malaysia\", \"finland\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"dominican_republic\", \"south_korea\", \"south_korea\", \"south_korea\", \"south_korea\", \"south_korea\", \"south_korea\", \"south_korea\", \"south_korea\", \"south_korea\", \"south_korea\", \"south_korea\", \"tunisia\", \"malta\", \"malta\", \"estonia\", \"estonia\", \"estonia\", \"estonia\", \"sudan\", \"bhutan\", \"bhutan\", \"bhutan\", \"bhutan\", \"peru\", \"peru\", \"peru\", \"peru\", \"peru\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"kazakhstan\", \"el_salvador\", \"el_salvador\", \"ireland\", \"ireland\", \"ireland\", \"ireland\", \"ireland\", \"ireland\", \"oman\", \"oman\", \"austria\", \"austria\", \"austria\", \"austria\", \"mali\", \"mali\", \"mali\", \"mali\", \"guinea-bissau\", \"haiti\", \"argentina\", \"argentina\", \"argentina\", \"argentina\", \"argentina\", \"guatemala\", \"guatemala\", \"guatemala\", \"guatemala\", \"guatemala\", \"ivory_coast\", \"qatar\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"s\\u00e3o_tom\\u00e9_and_pr\\u00edncipe\", \"s\\u00e3o_tom\\u00e9_and_pr\\u00edncipe\", \"s\\u00e3o_tom\\u00e9_and_pr\\u00edncipe\", \"s\\u00e3o_tom\\u00e9_and_pr\\u00edncipe\", \"croatia\", \"croatia\", \"croatia\", \"croatia\", \"croatia\", \"croatia\", \"croatia\", \"croatia\", \"croatia\", \"croatia\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"new_zealand\", \"new_zealand\", \"new_zealand\", \"new_zealand\", \"new_zealand\", \"new_zealand\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"mongolia\", \"mongolia\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"israel\", \"kenya\", \"kenya\", \"kenya\", \"kenya\", \"kenya\", \"kenya\", \"kenya\", \"kenya\", \"kenya\", \"kenya\", \"kenya\", \"rwanda\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"albania\", \"fiji\", \"fiji\", \"bahrain\", \"bahrain\", \"saint_lucia\", \"panama\", \"germany\", \"germany\", \"portugal\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"united_kingdom\", \"somalia\", \"somalia\", \"belgium\", \"belgium\", \"belgium\", \"botswana\", \"botswana\", \"united_arab_emirates\", \"united_arab_emirates\", \"united_arab_emirates\", \"denmark\", \"denmark\", \"denmark\", \"denmark\", \"chile\", \"chile\", \"chile\", \"chile\", \"chile\", \"chile\", \"chile\", \"chile\", \"chile\", \"togo\", \"togo\", \"togo\", \"togo\", \"togo\", \"togo\", \"togo\", \"togo\", \"togo\", \"togo\", \"togo\", \"togo\", \"togo\", \"togo\", \"togo\", \"togo\", \"togo\", \"moldova\", \"moldova\", \"italy\", \"italy\", \"italy\", \"italy\", \"italy\", \"italy\", \"italy\", \"italy\", \"italy\", \"italy\", \"italy\", \"italy\", \"comoros\", \"georgia\", \"georgia\", \"georgia\", \"georgia\", \"georgia\", \"georgia\", \"georgia\", \"georgia\", \"georgia\", \"brunei\", \"brunei\", \"brunei\", \"brunei\", \"eritrea\", \"chad\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"egypt\", \"egypt\", \"egypt\", \"egypt\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"mauritius\", \"uganda\", \"angola\", \"cambodia\", \"cambodia\", \"cambodia\", \"cambodia\", \"cambodia\", \"turkey\", \"turkey\", \"turkey\", \"turkey\", \"turkey\", \"turkey\", \"turkey\", \"turkey\", \"ecuador\", \"ecuador\", \"ecuador\", \"ecuador\", \"ecuador\", \"ecuador\", \"ecuador\", \"ecuador\", \"poland\", \"poland\", \"poland\", \"poland\", \"russia\", \"russia\", \"russia\", \"russia\", \"saint_vincent_and_grenadines\", \"saint_vincent_and_grenadines\", \"saint_vincent_and_grenadines\", \"saint_vincent_and_grenadines\", \"saint_vincent_and_grenadines\", \"saint_vincent_and_grenadines\", \"saint_vincent_and_grenadines\", \"saint_vincent_and_grenadines\", \"saint_vincent_and_grenadines\", \"saint_vincent_and_grenadines\", \"saint_vincent_and_grenadines\", \"ghana\", \"ghana\", \"ghana\", \"ghana\", \"ghana\", \"belarus\", \"belarus\", \"belarus\", \"belarus\", \"belarus\", \"sweden\", \"sweden\", \"sweden\", \"sweden\", \"sweden\", \"costa_rica\", \"costa_rica\", \"costa_rica\", \"costa_rica\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"greece\", \"greece\", \"greece\", \"greece\", \"greece\", \"greece\", \"greece\", \"greece\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"thailand\", \"thailand\", \"thailand\", \"thailand\", \"thailand\", \"myanmar\", \"myanmar\", \"myanmar\", \"myanmar\", \"myanmar\", \"myanmar\", \"benin\", \"benin\", \"benin\", \"ukraine\", \"ukraine\", \"ukraine\", \"ukraine\", \"ukraine\", \"ukraine\", \"ukraine\", \"ukraine\", \"ukraine\", \"barbados\", \"barbados\", \"barbados\", \"barbados\", \"sri_lanka\", \"sri_lanka\", \"bangladesh\", \"bangladesh\", \"bangladesh\", \"bangladesh\", \"bangladesh\", \"holy_see\", \"holy_see\", \"holy_see\", \"holy_see\", \"sudan\", \"romania\", \"romania\", \"romania\", \"romania\", \"romania\", \"romania\", \"romania\", \"romania\", \"romania\", \"republic_of_congo\", \"republic_of_congo\", \"republic_of_congo\", \"republic_of_congo\", \"republic_of_congo\", \"indonesia\", \"indonesia\", \"indonesia\", \"indonesia\", \"indonesia\", \"indonesia\", \"netherlands\", \"netherlands\", \"netherlands\", \"netherlands\", \"afghanistan\", \"afghanistan\", \"afghanistan\", \"afghanistan\", \"afghanistan\", \"morocco\", \"morocco\", \"morocco\", \"morocco\", \"morocco\", \"morocco\", \"morocco\", \"morocco\", \"morocco\", \"lithuania\", \"lithuania\", \"lithuania\", \"nepal\", \"nepal\", \"colombia\", \"colombia\", \"colombia\", \"colombia\", \"colombia\", \"colombia\", \"colombia\", \"colombia\", \"colombia\", \"colombia\", \"colombia\", \"colombia\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"cuba\", \"honduras\", \"honduras\", \"honduras\", \"honduras\", \"honduras\", \"honduras\", \"honduras\", \"honduras\", \"honduras\", \"honduras\", \"honduras\", \"spain\", \"spain\", \"spain\", \"spain\", \"spain\", \"spain\", \"spain\", \"spain\", \"east_timor\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"iran\", \"norway\", \"norway\", \"norway\", \"norway\", \"norway\", \"norway\", \"norway\", \"norway\", \"norway\", \"norway\", \"norway\", \"norway\", \"norway\", \"bosnia_and_herzegovina\", \"bosnia_and_herzegovina\", \"bosnia_and_herzegovina\", \"bosnia_and_herzegovina\", \"bosnia_and_herzegovina\", \"bosnia_and_herzegovina\", \"cyprus\", \"cyprus\", \"malawi\", \"malawi\", \"malawi\", \"malawi\", \"malawi\", \"malawi\", \"malawi\", \"malawi\", \"malawi\", \"malawi\", \"malawi\", \"malawi\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"algeria\", \"algeria\", \"algeria\", \"algeria\", \"algeria\", \"algeria\", \"palau\", \"palau\", \"belize\", \"belize\", \"belize\", \"belize\", \"belize\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"tajikistan\", \"paraguay\", \"trinidad_and_tobago\", \"trinidad_and_tobago\", \"trinidad_and_tobago\", \"trinidad_and_tobago\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\", \"saudi_arabia\"], \"legendgroup\": \"\", \"locations\": [\"UZB\", \"UZB\", \"UZB\", \"UZB\", \"UZB\", \"UZB\", \"UZB\", \"UZB\", \"YEM\", \"YEM\", \"YEM\", \"VUT\", \"VUT\", \"VUT\", \"ZMB\", \"ZMB\", \"ZMB\", \"ZMB\", \"ZMB\", \"ZMB\", \"ZMB\", \"ZMB\", \"ZMB\", \"VNM\", \"VNM\", \"VNM\", \"VNM\", \"VNM\", \"VNM\", \"VNM\", \"VNM\", \"VNM\", \"VNM\", \"VEN\", \"VEN\", \"VEN\", \"VEN\", \"VEN\", \"VEN\", \"VEN\", \"VEN\", \"VEN\", \"VEN\", \"VEN\", \"URY\", \"RUS\", \"RUS\", \"RUS\", \"RUS\", \"IRQ\", \"IRQ\", \"IRQ\", \"IRQ\", \"IRQ\", \"IRQ\", \"ISL\", \"LBY\", \"LBY\", \"LBY\", \"LBY\", \"LBY\", \"LBY\", \"LBY\", \"LBY\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"SVK\", \"SEN\", \"SEN\", \"MNE\", \"MNE\", \"KWT\", \"KWT\", \"BFA\", \"BFA\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"GRD\", \"GRD\", \"PHL\", \"PHL\", \"PHL\", \"PHL\", \"PHL\", \"PHL\", \"FRA\", \"FRA\", \"FRA\", \"FRA\", \"FRA\", \"FRA\", \"FRA\", \"FRA\", \"CAF\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"Not Available\", \"Not Available\", \"AZE\", \"HUN\", \"SGP\", \"SGP\", \"NER\", \"TON\", \"TON\", \"TON\", \"TON\", \"TON\", \"TON\", \"TON\", \"TON\", \"TON\", \"TON\", \"TON\", \"TON\", \"TON\", \"TON\", \"TON\", \"ZAF\", \"ZAF\", \"ZAF\", \"ZAF\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"BGR\", \"BGR\", \"LBN\", \"LBN\", \"LBN\", \"LBN\", \"JOR\", \"JOR\", \"SRB\", \"SRB\", \"SRB\", \"SRB\", \"SRB\", \"SRB\", \"SRB\", \"SRB\", \"SRB\", \"SRB\", \"SRB\", \"SRB\", \"SRB\", \"SRB\", \"SRB\", \"SRB\", \"GNB\", \"MYS\", \"MYS\", \"MYS\", \"MYS\", \"MYS\", \"MYS\", \"MYS\", \"MYS\", \"MYS\", \"MYS\", \"FIN\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"DOM\", \"PRK\", \"PRK\", \"PRK\", \"PRK\", \"PRK\", \"PRK\", \"PRK\", \"PRK\", \"PRK\", \"PRK\", \"PRK\", \"TUN\", \"MLT\", \"MLT\", \"EST\", \"EST\", \"EST\", \"EST\", \"SDN\", \"BTN\", \"BTN\", \"BTN\", \"BTN\", \"PER\", \"PER\", \"PER\", \"PER\", \"PER\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"KAZ\", \"SLV\", \"SLV\", \"IRL\", \"IRL\", \"IRL\", \"IRL\", \"IRL\", \"IRL\", \"OMN\", \"OMN\", \"AUT\", \"AUT\", \"AUT\", \"AUT\", \"MLI\", \"MLI\", \"MLI\", \"MLI\", \"GNB\", \"HTI\", \"ARG\", \"ARG\", \"ARG\", \"ARG\", \"ARG\", \"GTM\", \"GTM\", \"GTM\", \"GTM\", \"GTM\", \"CIV\", \"QAT\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"Not Available\", \"Not Available\", \"Not Available\", \"Not Available\", \"HRV\", \"HRV\", \"HRV\", \"HRV\", \"HRV\", \"HRV\", \"HRV\", \"HRV\", \"HRV\", \"HRV\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"JPN\", \"NZL\", \"NZL\", \"NZL\", \"NZL\", \"NZL\", \"NZL\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"MNG\", \"MNG\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"CAN\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"ISR\", \"KEN\", \"KEN\", \"KEN\", \"KEN\", \"KEN\", \"KEN\", \"KEN\", \"KEN\", \"KEN\", \"KEN\", \"KEN\", \"RWA\", \"BRA\", \"BRA\", \"BRA\", \"BRA\", \"BRA\", \"BRA\", \"BRA\", \"BRA\", \"BRA\", \"BRA\", \"BRA\", \"BRA\", \"BRA\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"ALB\", \"FJI\", \"FJI\", \"BHR\", \"BHR\", \"LCA\", \"PAN\", \"DEU\", \"DEU\", \"PRT\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"GBR\", \"SOM\", \"SOM\", \"BEL\", \"BEL\", \"BEL\", \"BWA\", \"BWA\", \"ARE\", \"ARE\", \"ARE\", \"DNK\", \"DNK\", \"DNK\", \"DNK\", \"CHL\", \"CHL\", \"CHL\", \"CHL\", \"CHL\", \"CHL\", \"CHL\", \"CHL\", \"CHL\", \"TGO\", \"TGO\", \"TGO\", \"TGO\", \"TGO\", \"TGO\", \"TGO\", \"TGO\", \"TGO\", \"TGO\", \"TGO\", \"TGO\", \"TGO\", \"TGO\", \"TGO\", \"TGO\", \"TGO\", \"MDA\", \"MDA\", \"ITA\", \"ITA\", \"ITA\", \"ITA\", \"ITA\", \"ITA\", \"ITA\", \"ITA\", \"ITA\", \"ITA\", \"ITA\", \"ITA\", \"COM\", \"GEO\", \"GEO\", \"GEO\", \"GEO\", \"GEO\", \"GEO\", \"GEO\", \"GEO\", \"GEO\", \"Not Available\", \"Not Available\", \"Not Available\", \"Not Available\", \"ERI\", \"TCD\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"EGY\", \"EGY\", \"EGY\", \"EGY\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"MUS\", \"UGA\", \"AGO\", \"KHM\", \"KHM\", \"KHM\", \"KHM\", \"KHM\", \"TUR\", \"TUR\", \"TUR\", \"TUR\", \"TUR\", \"TUR\", \"TUR\", \"TUR\", \"ECU\", \"ECU\", \"ECU\", \"ECU\", \"ECU\", \"ECU\", \"ECU\", \"ECU\", \"POL\", \"POL\", \"POL\", \"POL\", \"RUS\", \"RUS\", \"RUS\", \"RUS\", \"VCT\", \"VCT\", \"VCT\", \"VCT\", \"VCT\", \"VCT\", \"VCT\", \"VCT\", \"VCT\", \"VCT\", \"VCT\", \"GHA\", \"GHA\", \"GHA\", \"GHA\", \"GHA\", \"BLR\", \"BLR\", \"BLR\", \"BLR\", \"BLR\", \"SWE\", \"SWE\", \"SWE\", \"SWE\", \"SWE\", \"CRI\", \"CRI\", \"CRI\", \"CRI\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"IND\", \"GRC\", \"GRC\", \"GRC\", \"GRC\", \"GRC\", \"GRC\", \"GRC\", \"GRC\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"MEX\", \"THA\", \"THA\", \"THA\", \"THA\", \"THA\", \"MMR\", \"MMR\", \"MMR\", \"MMR\", \"MMR\", \"MMR\", \"BEN\", \"BEN\", \"BEN\", \"UKR\", \"UKR\", \"UKR\", \"UKR\", \"UKR\", \"UKR\", \"UKR\", \"UKR\", \"UKR\", \"BRB\", \"BRB\", \"BRB\", \"BRB\", \"LKA\", \"LKA\", \"BGD\", \"BGD\", \"BGD\", \"BGD\", \"BGD\", \"VAT\", \"VAT\", \"VAT\", \"VAT\", \"SDN\", \"ROU\", \"ROU\", \"ROU\", \"ROU\", \"ROU\", \"ROU\", \"ROU\", \"ROU\", \"ROU\", \"COG\", \"COG\", \"COG\", \"COG\", \"COG\", \"IDN\", \"IDN\", \"IDN\", \"IDN\", \"IDN\", \"IDN\", \"NLD\", \"NLD\", \"NLD\", \"NLD\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"MAR\", \"MAR\", \"MAR\", \"MAR\", \"MAR\", \"MAR\", \"MAR\", \"MAR\", \"MAR\", \"LTU\", \"LTU\", \"LTU\", \"NPL\", \"NPL\", \"COL\", \"COL\", \"COL\", \"COL\", \"COL\", \"COL\", \"COL\", \"COL\", \"COL\", \"COL\", \"COL\", \"COL\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"CUB\", \"HND\", \"HND\", \"HND\", \"HND\", \"HND\", \"HND\", \"HND\", \"HND\", \"HND\", \"HND\", \"HND\", \"ESP\", \"ESP\", \"ESP\", \"ESP\", \"ESP\", \"ESP\", \"ESP\", \"ESP\", \"TLS\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"IRN\", \"NOR\", \"NOR\", \"NOR\", \"NOR\", \"NOR\", \"NOR\", \"NOR\", \"NOR\", \"NOR\", \"NOR\", \"NOR\", \"NOR\", \"NOR\", \"BIH\", \"BIH\", \"BIH\", \"BIH\", \"BIH\", \"BIH\", \"CYP\", \"CYP\", \"MWI\", \"MWI\", \"MWI\", \"MWI\", \"MWI\", \"MWI\", \"MWI\", \"MWI\", \"MWI\", \"MWI\", \"MWI\", \"MWI\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"PAK\", \"DZA\", \"DZA\", \"DZA\", \"DZA\", \"DZA\", \"DZA\", \"PLW\", \"PLW\", \"BLZ\", \"BLZ\", \"BLZ\", \"BLZ\", \"BLZ\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"CHN\", \"TJK\", \"PRY\", \"TTO\", \"TTO\", \"TTO\", \"TTO\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\", \"SAU\"], \"marker\": {\"color\": [0.9903278350830078, 0.9258717894554138, 0.03301486372947693, 0.9802740812301636, 0.4777415096759796, 0.988888680934906, 0.988916277885437, 0.9819125533103943, 0.03735635429620743, 0.09942951053380966, 0.1228761076927185, 0.6797173619270325, 0.9803004860877991, 0.9903771281242371, 0.9902564883232117, 0.9763308167457581, 0.5212607383728027, 0.03808004409074783, 0.983282208442688, 0.9061954021453857, 0.31913211941719055, 0.9778064489364624, 0.9545751810073853, 0.9887194037437439, 0.9865584969520569, 0.9895386695861816, 0.3730819523334503, 0.9710715413093567, 0.9722254276275635, 0.9654565453529358, 0.988295316696167, 0.980549156665802, 0.8865543007850647, 0.8789016008377075, 0.6558321118354797, 0.9869552850723267, 0.9600448608398438, 0.013157621957361698, 0.02311776578426361, 0.9357139468193054, 0.013683650642633438, 0.08746157586574554, 0.09506958723068237, 0.020944947376847267, 0.9743028879165649, 0.9242598414421082, 0.9835892915725708, 0.01635131798684597, 0.013922506012022495, 0.9882948398590088, 0.9876456260681152, 0.9855538010597229, 0.044090647250413895, 0.9768977165222168, 0.9907414317131042, 0.9894940853118896, 0.5034304857254028, 0.985800564289093, 0.06235779821872711, 0.041487377136945724, 0.031916823238134384, 0.8965003490447998, 0.06193956732749939, 0.0769646167755127, 0.9639303088188171, 0.9729312658309937, 0.9886718392372131, 0.9904402494430542, 0.9876677989959717, 0.9875011444091797, 0.07457474619150162, 0.017027540132403374, 0.01653827354311943, 0.015336062759160995, 0.013809616677463055, 0.02052626945078373, 0.984883189201355, 0.9882239103317261, 0.9750896692276001, 0.9857234954833984, 0.986883819103241, 0.9907961487770081, 0.9904657006263733, 0.9904651045799255, 0.94557785987854, 0.02795945666730404, 0.988933801651001, 0.9875715374946594, 0.9839296936988831, 0.16088160872459412, 0.9724045991897583, 0.7853917479515076, 0.050770729780197144, 0.9587175250053406, 0.9811742305755615, 0.9204964637756348, 0.9218602180480957, 0.4246077239513397, 0.9843471646308899, 0.9902143478393555, 0.9862114787101746, 0.9234774708747864, 0.47251707315444946, 0.908193826675415, 0.9357872605323792, 0.9915353059768677, 0.9807658791542053, 0.03220202028751373, 0.9785273671150208, 0.9849993586540222, 0.9898694157600403, 0.04115939512848854, 0.9873039126396179, 0.34171801805496216, 0.987754225730896, 0.990883469581604, 0.02726256288588047, 0.9887055158615112, 0.8210367560386658, 0.5513240694999695, 0.8592293858528137, 0.9882355332374573, 0.8448930978775024, 0.9048131108283997, 0.8458470106124878, 0.7695845365524292, 0.5997339487075806, 0.9906385540962219, 0.9762527346611023, 0.9306373596191406, 0.9681133031845093, 0.9872229695320129, 0.01641753315925598, 0.09327973425388336, 0.9782524704933167, 0.9893156290054321, 0.22872819006443024, 0.8581562638282776, 0.5749895572662354, 0.9904399514198303, 0.4403957426548004, 0.9514491558074951, 0.8380817770957947, 0.9894313216209412, 0.4528568685054779, 0.6470261216163635, 0.9904924035072327, 0.08342763036489487, 0.8712990283966064, 0.9895274639129639, 0.9891878962516785, 0.9898216724395752, 0.973922610282898, 0.982810914516449, 0.9895809888839722, 0.9326935410499573, 0.41604411602020264, 0.1079876497387886, 0.9813465476036072, 0.44259113073349, 0.9865728616714478, 0.14630456268787384, 0.022688087075948715, 0.6051450967788696, 0.9885494112968445, 0.9883970022201538, 0.9752487540245056, 0.981093168258667, 0.9857863187789917, 0.9889436364173889, 0.3482884466648102, 0.9894099831581116, 0.9224351048469543, 0.957499623298645, 0.9899859428405762, 0.9263967275619507, 0.19556447863578796, 0.9844622611999512, 0.5421558022499084, 0.989896297454834, 0.9724631309509277, 0.29050108790397644, 0.7004779577255249, 0.017489515244960785, 0.9451194405555725, 0.22358523309230804, 0.9620206952095032, 0.9803941249847412, 0.9897805452346802, 0.9884350299835205, 0.6521075367927551, 0.5459848046302795, 0.8907711505889893, 0.11660991609096527, 0.02177281118929386, 0.5086423754692078, 0.9661024808883667, 0.9871200323104858, 0.021049384027719498, 0.9789365530014038, 0.9725486636161804, 0.9871951341629028, 0.9821212291717529, 0.9896422028541565, 0.019082145765423775, 0.07268048822879791, 0.5657462477684021, 0.02848239615559578, 0.954003632068634, 0.9791343212127686, 0.9785959124565125, 0.6985103487968445, 0.9887563586235046, 0.9569060802459717, 0.9728441834449768, 0.8787362575531006, 0.01714467629790306, 0.14665010571479797, 0.019065983593463898, 0.7969222664833069, 0.9172483086585999, 0.9638944864273071, 0.016521714627742767, 0.1396186798810959, 0.07040997594594955, 0.9627969861030579, 0.10718654096126556, 0.9899077415466309, 0.9653310775756836, 0.6278465390205383, 0.9722518920898438, 0.9892410039901733, 0.8594865202903748, 0.7541614174842834, 0.9824055433273315, 0.9892832636833191, 0.9703730344772339, 0.9867457747459412, 0.9610044956207275, 0.8763214349746704, 0.97705078125, 0.9904556274414062, 0.7856296896934509, 0.9755927324295044, 0.9868203997612, 0.9903814792633057, 0.6070419549942017, 0.9875897169113159, 0.990972101688385, 0.9893280267715454, 0.7920608520507812, 0.07353918254375458, 0.9891234040260315, 0.9841702580451965, 0.9080819487571716, 0.9899277687072754, 0.02817760407924652, 0.18510331213474274, 0.9840636253356934, 0.9019745588302612, 0.111836738884449, 0.9897711873054504, 0.2632521390914917, 0.9663383960723877, 0.9867244362831116, 0.27558693289756775, 0.9888103008270264, 0.9779835343360901, 0.8943707942962646, 0.22402574121952057, 0.9832348227500916, 0.92410808801651, 0.5349011421203613, 0.9881870150566101, 0.3195624351501465, 0.7518832087516785, 0.022225873544812202, 0.9785334467887878, 0.9814077615737915, 0.10552206635475159, 0.7685574293136597, 0.9160683751106262, 0.03128228336572647, 0.028210647404193878, 0.9715816974639893, 0.9877176880836487, 0.9851261377334595, 0.9744296073913574, 0.6378013491630554, 0.9760396480560303, 0.04848095029592514, 0.9292526841163635, 0.9885615706443787, 0.5763952136039734, 0.9883288145065308, 0.9605723023414612, 0.9302486181259155, 0.8821088075637817, 0.03185493126511574, 0.9795863628387451, 0.9626197814941406, 0.859560489654541, 0.3690294623374939, 0.9836251735687256, 0.26670095324516296, 0.9805530905723572, 0.7652795314788818, 0.3035966753959656, 0.9033697843551636, 0.09740804135799408, 0.8689233064651489, 0.052671194076538086, 0.324249267578125, 0.9902294278144836, 0.9858340620994568, 0.822955846786499, 0.9886311292648315, 0.9872759580612183, 0.9860461950302124, 0.4332980215549469, 0.5179227590560913, 0.021001407876610756, 0.12555627524852753, 0.2044258564710617, 0.13913187384605408, 0.017372457310557365, 0.14120616018772125, 0.9844555258750916, 0.08286195248365402, 0.98853999376297, 0.38979509472846985, 0.9315413236618042, 0.16674065589904785, 0.9857260584831238, 0.9912551641464233, 0.17524729669094086, 0.987005889415741, 0.9874380230903625, 0.9890842437744141, 0.9904338121414185, 0.9845537543296814, 0.9885907173156738, 0.892879843711853, 0.9875426292419434, 0.9855874180793762, 0.9880533814430237, 0.9901731014251709, 0.14228029549121857, 0.9894454479217529, 0.9803882241249084, 0.983103334903717, 0.9887873530387878, 0.9711689949035645, 0.9856598973274231, 0.9608017802238464, 0.22926226258277893, 0.9900932908058167, 0.988182008266449, 0.982263445854187, 0.9903508424758911, 0.9079728126525879, 0.989981472492218, 0.9888653755187988, 0.9834238886833191, 0.9639303088188171, 0.9729312658309937, 0.9886718392372131, 0.9904402494430542, 0.9876677989959717, 0.9875011444091797, 0.02007819153368473, 0.017027540132403374, 0.01653827354311943, 0.015336062759160995, 0.013809616677463055, 0.02052626945078373, 0.984883189201355, 0.9882239103317261, 0.9750896692276001, 0.9857234954833984, 0.986883819103241, 0.9907961487770081, 0.9904657006263733, 0.9904651045799255, 0.94557785987854, 0.9759677052497864, 0.9732282161712646, 0.9839574098587036, 0.9476821422576904, 0.8430238366127014, 0.9902473092079163, 0.9892764687538147, 0.46024397015571594, 0.039679937064647675, 0.8970088958740234, 0.052182309329509735, 0.9436042904853821, 0.4299856424331665, 0.05873885750770569, 0.7843363285064697, 0.14389130473136902, 0.7214798331260681, 0.9757146239280701, 0.9282270073890686, 0.4098474979400635, 0.9573317766189575, 0.9869728088378906, 0.7787234783172607, 0.15199494361877441, 0.8028212785720825, 0.7450935244560242, 0.9886122941970825, 0.9886592030525208, 0.023268839344382286, 0.022711927071213722, 0.9896419644355774, 0.22296933829784393, 0.9698293209075928, 0.03585207834839821, 0.9701481461524963, 0.9819139242172241, 0.8929833173751831, 0.8010050058364868, 0.9810172319412231, 0.8384777307510376, 0.9097244739532471, 0.9723595976829529, 0.9887194037437439, 0.01818050816655159, 0.6138487458229065, 0.897489607334137, 0.9873194694519043, 0.9876920580863953, 0.8577781319618225, 0.2589390277862549, 0.05890251323580742, 0.9695608019828796, 0.11756999790668488, 0.9811742305755615, 0.9204964637756348, 0.9218602180480957, 0.4246077239513397, 0.9843471646308899, 0.9902143478393555, 0.9862114787101746, 0.9234774708747864, 0.47251707315444946, 0.908193826675415, 0.9357872605323792, 0.9915353059768677, 0.9807658791542053, 0.03220202028751373, 0.9785273671150208, 0.9781305193901062, 0.9799166917800903, 0.028042038902640343, 0.7956790924072266, 0.8650113344192505, 0.6108077764511108, 0.023920297622680664, 0.9823033809661865, 0.9876580834388733, 0.952962338924408, 0.9889585375785828, 0.7129408121109009, 0.3124614655971527, 0.730099081993103, 0.9660577178001404, 0.03962785005569458, 0.3921063244342804, 0.05632935091853142, 0.7722805738449097, 0.989997148513794, 0.9885849356651306, 0.9882580041885376, 0.9807397723197937, 0.9875395894050598, 0.9537498950958252, 0.6519265174865723, 0.9879069924354553, 0.9859737753868103, 0.5179340839385986, 0.39931315183639526, 0.9817333817481995, 0.9894298315048218, 0.98477703332901, 0.8645102977752686, 0.15212339162826538, 0.9882342219352722, 0.016819925978779793, 0.9899340867996216, 0.989112377166748, 0.9717244505882263, 0.8660255670547485, 0.988137423992157, 0.9114149212837219, 0.9894125461578369, 0.42134547233581543, 0.17708182334899902, 0.7658159732818604, 0.10857371240854263, 0.7851555347442627, 0.1416555643081665, 0.9781354665756226, 0.8195919394493103, 0.6109755635261536, 0.05792050063610077, 0.9874544739723206, 0.9044705629348755, 0.9473594427108765, 0.10613187402486801, 0.9909771680831909, 0.9555771946907043, 0.9857863187789917, 0.9889436364173889, 0.3482884466648102, 0.9894099831581116, 0.9224351048469543, 0.957499623298645, 0.9899859428405762, 0.9263967275619507, 0.19556447863578796, 0.9844622611999512, 0.5421558022499084, 0.989896297454834, 0.022579455748200417, 0.509384036064148, 0.9887822270393372, 0.990574061870575, 0.18996986746788025, 0.9273965954780579, 0.06560828536748886, 0.8808094263076782, 0.5810150504112244, 0.9853407740592957, 0.9900805354118347, 0.9905087947845459, 0.9898239374160767, 0.889666736125946, 0.9860817790031433, 0.20969825983047485, 0.3729129731655121, 0.9854027032852173, 0.9694024920463562, 0.9899145364761353, 0.9909054040908813, 0.2721935510635376, 0.07115723937749863, 0.9778724312782288, 0.9670576453208923, 0.9865425229072571, 0.987371027469635, 0.03152240812778473, 0.986319899559021, 0.5847445130348206, 0.9883825778961182, 0.8917126059532166, 0.019772004336118698, 0.9904140830039978, 0.978605329990387, 0.8112959265708923, 0.9895926117897034, 0.7878127694129944, 0.9875370860099792, 0.276167094707489, 0.3002362549304962, 0.03154119476675987, 0.9904655814170837, 0.9913318753242493, 0.014283991418778896, 0.9903634190559387, 0.01352929137647152, 0.503432035446167, 0.980573832988739, 0.976589024066925, 0.989486575126648, 0.9789572954177856, 0.560180127620697, 0.9852286577224731, 0.05202796682715416, 0.9856074452400208, 0.08406779915094376, 0.848484456539154, 0.9856867790222168, 0.901435136795044, 0.9769334197044373, 0.044524043798446655, 0.9881206154823303, 0.40328317880630493, 0.964328408241272, 0.9901968240737915, 0.9906971454620361, 0.9890953302383423, 0.974462628364563, 0.14789660274982452, 0.4528540372848511, 0.8824478983879089, 0.8128299713134766, 0.04071880131959915, 0.9834302663803101, 0.7359244227409363, 0.8960778713226318, 0.023516902700066566, 0.19404922425746918, 0.08419648557901382, 0.9754515290260315, 0.08104553818702698, 0.9903993606567383, 0.017310334369540215, 0.05677559971809387, 0.02586757019162178, 0.02040805295109749, 0.017384855076670647, 0.012646062299609184, 0.9881511330604553, 0.5016931295394897, 0.3687368929386139, 0.02457474172115326, 0.9080262780189514, 0.08842717111110687, 0.9724220037460327, 0.15031620860099792, 0.7610234022140503, 0.1820565164089203, 0.9826421141624451, 0.1363835483789444, 0.5292624831199646, 0.9786518216133118, 0.0907529667019844, 0.07756438106298447, 0.8147468566894531, 0.9871329069137573, 0.9867480993270874, 0.16031873226165771, 0.9524646997451782, 0.987207293510437, 0.9799507856369019, 0.9349325299263, 0.8727374076843262, 0.578964352607727, 0.17514532804489136, 0.20400696992874146, 0.6723362803459167, 0.9873886704444885, 0.9884229898452759, 0.14808988571166992, 0.9887104630470276, 0.9822072982788086, 0.9872356653213501, 0.04707927629351616, 0.9814052581787109, 0.022020142525434494, 0.9872102737426758, 0.9795715808868408, 0.1434665024280548, 0.9272876977920532, 0.4709349274635315, 0.2355806529521942, 0.46343302726745605, 0.33750542998313904, 0.44548094272613525, 0.9872523546218872, 0.4302810728549957, 0.04728399217128754, 0.9741637110710144, 0.907549262046814, 0.020912369713187218, 0.022914208471775055, 0.388253390789032, 0.9827252626419067, 0.7623032927513123, 0.9665835499763489, 0.6512706875801086, 0.9562662243843079, 0.1313590109348297, 0.058946773409843445, 0.04018880054354668, 0.15563713014125824, 0.9240553975105286, 0.8070000410079956, 0.7771458625793457, 0.975493311882019, 0.7359195947647095, 0.6883528232574463, 0.21606793999671936, 0.019260838627815247, 0.7859871983528137, 0.01574852131307125, 0.8847048878669739, 0.9846776127815247, 0.9889479875564575, 0.025094997137784958, 0.9242598414421082, 0.9835892915725708, 0.01635131798684597, 0.013922506012022495, 0.9640732407569885, 0.9877225756645203, 0.13877533376216888, 0.4393870532512665, 0.9782152771949768, 0.9402454495429993, 0.9871259331703186, 0.9269280433654785, 0.9880780577659607, 0.256672203540802, 0.062082864344120026, 0.021666819229722023, 0.017571888864040375, 0.9355859160423279, 0.03229382261633873, 0.9822376370429993, 0.9373941421508789, 0.013868367299437523, 0.9007307887077332, 0.9873245358467102, 0.03544735535979271, 0.9639775156974792, 0.2399943470954895, 0.8890633583068848, 0.595383882522583, 0.9893636703491211, 0.08566228300333023, 0.044811468571424484, 0.9858337640762329, 0.9507176280021667, 0.983103334903717, 0.9887873530387878, 0.9711689949035645, 0.9856598973274231, 0.9608017802238464, 0.22926226258277893, 0.9900932908058167, 0.988182008266449, 0.982263445854187, 0.9903508424758911, 0.9079728126525879, 0.989981472492218, 0.9888653755187988, 0.9834238886833191, 0.9758360385894775, 0.9909006953239441, 0.9858178496360779, 0.7971238493919373, 0.9853962063789368, 0.03659089654684067, 0.9899695515632629, 0.9887212514877319, 0.9904050827026367, 0.9709647297859192, 0.977843701839447, 0.8883665204048157, 0.6371217966079712, 0.943855881690979, 0.9873794913291931, 0.9892082214355469, 0.9466489553451538, 0.9815812706947327, 0.9737735390663147, 0.4347488582134247, 0.9835785031318665, 0.8886511325836182, 0.9267269968986511, 0.9734275937080383, 0.8882107138633728, 0.9880711436271667, 0.8239160180091858, 0.19809207320213318, 0.5774911046028137, 0.019326025620102882, 0.024929992854595184, 0.4669252038002014, 0.21436481177806854, 0.9905490279197693, 0.9877080321311951, 0.8063652515411377, 0.9911335706710815, 0.9850022792816162, 0.7584715485572815, 0.2613803744316101, 0.9885401725769043, 0.08645455539226532, 0.9687811136245728, 0.026984691619873047, 0.9795407056808472, 0.4016317129135132, 0.9904619455337524, 0.05909982696175575, 0.9902268052101135, 0.5945145487785339, 0.9643102884292603, 0.9856909513473511, 0.6487022638320923, 0.9704917073249817, 0.9767587780952454, 0.7936412692070007, 0.9835706949234009, 0.9891948699951172, 0.0579475574195385, 0.9828832745552063, 0.9834128022193909, 0.41096287965774536, 0.0675944834947586, 0.07353918254375458, 0.9649674296379089, 0.9903460741043091, 0.4955957233905792, 0.9896215796470642, 0.9871959686279297, 0.9888815879821777, 0.5769312381744385, 0.7797951698303223, 0.49976325035095215, 0.9704691171646118, 0.803375244140625, 0.024510852992534637, 0.8138072490692139, 0.6603464484214783, 0.9903162121772766, 0.9741334915161133, 0.956796407699585, 0.9726621508598328, 0.9053788781166077, 0.16185635328292847, 0.027050675824284554, 0.4274677038192749, 0.043384213000535965, 0.8479809761047363, 0.6573129892349243, 0.9719684720039368, 0.9904764294624329, 0.9846212863922119, 0.07955542951822281, 0.984308123588562, 0.9893244504928589, 0.6794285774230957, 0.9882603883743286, 0.16638003289699554, 0.8782562017440796, 0.9869535565376282, 0.9884700179100037, 0.9541470408439636, 0.8901886940002441, 0.9896377325057983, 0.8762021064758301, 0.8000541925430298, 0.9879160523414612, 0.09631547331809998, 0.08588410168886185, 0.5615049004554749, 0.2913762032985687, 0.8302640914916992, 0.21056194603443146, 0.8463429808616638, 0.16841740906238556, 0.9802197217941284, 0.984642744064331, 0.9879260659217834, 0.9647554159164429, 0.01714467629790306, 0.14665010571479797, 0.019065983593463898, 0.7969222664833069, 0.9172483086585999, 0.9638944864273071, 0.016521714627742767, 0.1396186798810959, 0.07040997594594955, 0.9627969861030579, 0.10718654096126556, 0.9899077415466309, 0.9653310775756836, 0.6278465390205383, 0.9722518920898438, 0.9892410039901733, 0.15939156711101532, 0.9546576738357544, 0.8181811571121216, 0.01602996326982975, 0.16462914645671844, 0.8229138255119324, 0.9101958274841309, 0.0313139408826828, 0.01639704965054989, 0.8410821557044983, 0.5637220740318298, 0.3430420160293579, 0.433697372674942, 0.977927565574646, 0.14601784944534302, 0.21018020808696747, 0.43273797631263733, 0.37401512265205383, 0.9502963423728943, 0.987560510635376, 0.822955846786499, 0.9886311292648315, 0.9872759580612183, 0.9860461950302124, 0.4332980215549469, 0.5179227590560913, 0.021001407876610756, 0.12555627524852753, 0.2044258564710617, 0.13913187384605408, 0.017372457310557365, 0.14120616018772125, 0.9844555258750916, 0.08286195248365402, 0.98853999376297, 0.38979509472846985, 0.9315413236618042, 0.16674065589904785, 0.9857260584831238, 0.9912551641464233, 0.17524729669094086, 0.984144389629364, 0.9855290055274963, 0.9193755388259888, 0.9724627733230591, 0.7010658979415894, 0.15774005651474, 0.22546763718128204, 0.9402082562446594, 0.976028323173523, 0.9859723448753357, 0.9875497221946716, 0.986828088760376, 0.16622509062290192, 0.836868405342102, 0.9894653558731079, 0.8790926933288574, 0.7052581906318665, 0.9444901943206787, 0.9550608992576599, 0.9897828102111816, 0.97566157579422, 0.9295265078544617, 0.9376152157783508, 0.983517587184906, 0.8012567162513733, 0.32049819827079773, 0.9880966544151306, 0.7866527438163757, 0.986327588558197, 0.8559931516647339, 0.9825774431228638, 0.016153277829289436, 0.08676213771104813, 0.9892764687538147, 0.46024397015571594, 0.039679937064647675, 0.8970088958740234, 0.052182309329509735, 0.9436042904853821, 0.4299856424331665, 0.05873885750770569, 0.7843363285064697, 0.14389130473136902, 0.7214798331260681, 0.9757146239280701, 0.9282270073890686, 0.4098474979400635, 0.9573317766189575, 0.9869728088378906, 0.7787234783172607, 0.15199494361877441, 0.8634020686149597, 0.1129179447889328, 0.13670635223388672, 0.01629425399005413, 0.976590096950531, 0.9904043078422546, 0.9888054132461548, 0.9695947766304016, 0.8946252465248108, 0.06915779411792755, 0.9833933115005493, 0.9833025336265564, 0.9807903170585632, 0.6519265174865723, 0.9879069924354553, 0.9859737753868103, 0.5179340839385986, 0.39931315183639526, 0.9817333817481995, 0.9894298315048218, 0.98477703332901, 0.8645102977752686, 0.15212339162826538, 0.9882342219352722, 0.016819925978779793, 0.9899340867996216, 0.989112377166748, 0.9717244505882263, 0.8660255670547485, 0.988137423992157, 0.9114149212837219, 0.9894125461578369, 0.42134547233581543, 0.17708182334899902, 0.7658159732818604, 0.10857371240854263, 0.7851555347442627, 0.1416555643081665, 0.9710971713066101, 0.32647594809532166, 0.9894874095916748, 0.9835440516471863, 0.985260546207428, 0.8470490574836731, 0.4528540372848511, 0.8824478983879089, 0.8128299713134766, 0.04071880131959915, 0.9834302663803101, 0.7359244227409363, 0.8960778713226318, 0.023516902700066566, 0.19404922425746918, 0.08419648557901382, 0.9754515290260315, 0.08104553818702698, 0.9903993606567383, 0.017310334369540215, 0.05677559971809387, 0.02586757019162178, 0.02040805295109749, 0.017384855076670647, 0.012646062299609184, 0.9881511330604553, 0.5016931295394897, 0.3687368929386139, 0.02457474172115326, 0.9080262780189514, 0.08842717111110687, 0.9724220037460327, 0.15031620860099792, 0.7610234022140503, 0.1820565164089203, 0.9826421141624451, 0.1363835483789444, 0.5292624831199646], \"coloraxis\": \"coloraxis\"}, \"name\": \"\", \"showlegend\": false, \"type\": \"scattergeo\"}],\n",
              "                        {\"coloraxis\": {\"colorbar\": {\"title\": {\"text\": \"Predictions_Probas\"}}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"geo\": {\"center\": {}, \"domain\": {\"x\": [0.0, 1.0], \"y\": [0.0, 1.0]}, \"projection\": {\"type\": \"natural earth\"}, \"resolution\": 50}, \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('89bb0340-092e-4b1b-a377-dfe9270224ae');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owCGi7mk8hCk",
        "colab_type": "text"
      },
      "source": [
        "# Future improvements\n",
        "\n",
        "ALBERT is indeed a very impressive language model. I'm looking forward to replicate the success `Albert` has on the Wikipedia dataset to news headlines scrapped from the web. However, there are added layers of complexity that needs to be solved:\n",
        "\n",
        "* As explained earlier, we need to be able to differentiate facts from commentaries.\n",
        "\n",
        "* A simple Googling of \"United States - China\" relations might not return us results that are all relevant. An added element of effort needs to be put in to clean the dataset.\n",
        "\n",
        "Like any data scientist would do, a deeper analysis of the results can be conducted by analysing the precision/recall on the test dataset.\n",
        "\n",
        "That's it for now folks! If you have any questions/comments please feel free to reach out to me through [Linkedin](https://www.linkedin.com/in/kennethwangtm/) or email at ken.wangtm@gmail.com"
      ]
    }
  ]
}